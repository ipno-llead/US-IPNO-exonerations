{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "Image(filename='../data/banner.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tables\n",
    "\n",
    "# allContext (iterate over all of the content within the document with one api call)\n",
    "\n",
    "data_sonnet_fullcontext = pd.read_csv('../data/allContext/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet_fullcontext['analysis_type'] = 'fullcontext_sonnet'\n",
    "\n",
    "data_haiku_fullcontext = pd.read_csv('../data/allContext/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku_fullcontext['analysis_type'] = 'fullcontext_haiku'\n",
    "\n",
    "data_opus_fullcontext = pd.read_csv('../data/allContext/results_claude-3-opus-20240229.csv')\n",
    "data_opus_fullcontext['analysis_type'] = 'fullcontext_opus'\n",
    "\n",
    "# AllPages (iterate over each page with one api call per page)\n",
    "\n",
    "data_haiku = pd.read_csv('../data/allPages/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku['analysis_type'] = 'allpages_haiku'\n",
    "\n",
    "data_sonnet = pd.read_csv('../data/allPages/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet['analysis_type'] = 'allpages_sonnet'\n",
    "\n",
    "data_mixtral_7b = pd.read_csv('../data/allPages/Mixtral-8x7B-Instruct-v0.1.csv')\n",
    "data_mixtral_7b['analysis_type'] = 'allpages_mixtral_7b'\n",
    "\n",
    "data_mixtral_22b = pd.read_csv('../data/allPages/Mixtral-8x22B-Instruct-v0.1.csv')\n",
    "data_mixtral_22b['analysis_type'] = 'allpages_mixtral_22b'\n",
    "\n",
    "# use Named Entity Recognition (NER) to calculate the number of entities on each page as a preprocessing step. \n",
    "# It then processes the document in three separate iterations. \n",
    "# In each iteration, it focuses on different top fractions of pages containing the most entities: \n",
    "# first the top 1/4th, then the top 1/2, and finally the top 3/4ths of the document. \n",
    "# For each fraction, the script identifies the pages with the highest number of entities and then iterates over each of those pages, \n",
    "# similar to the allPages script, to extract the entities.\n",
    "\n",
    "data_haiku_25 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-25per.csv')\n",
    "data_haiku_25['analysis_type'] = 'ner_25_haiku'\n",
    "\n",
    "data_haiku_50 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-50per.csv')\n",
    "data_haiku_50['analysis_type'] = 'ner_50_haiku'\n",
    "\n",
    "data_haiku_75 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-75per.csv')\n",
    "data_haiku_75['analysis_type'] = 'ner_75_haiku'\n",
    "\n",
    "data_sonnet_25 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-25per.csv')\n",
    "data_sonnet_25['analysis_type'] = 'ner_25_sonnet'\n",
    "\n",
    "data_sonnet_50 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-50per.csv')\n",
    "data_sonnet_50['analysis_type'] = 'ner_50_sonnet'\n",
    "\n",
    "data_sonnet_75 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-75per.csv')\n",
    "data_sonnet_75['analysis_type'] = 'ner_75_sonnet'\n",
    "\n",
    "data_mixtral_7b_25 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_7b_25['analysis_type'] = 'ner_25_mixtral_7b'\n",
    "\n",
    "data_mixtral_7b_50 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_7b_50['analysis_type'] = 'ner_50_mixtral_7b'\n",
    "\n",
    "data_mixtral_7b_75 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_7b_75['analysis_type'] = 'ner_75_mixtral_7b'\n",
    "\n",
    "data_mixtral_22b_25 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_22b_25['analysis_type'] = 'ner_25_mixtral_22b'\n",
    "\n",
    "data_mixtral_22b_50 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_22b_50['analysis_type'] = 'ner_50_mixtral_22b'\n",
    "\n",
    "data_mixtral_22b_75 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_22b_75['analysis_type'] = 'ner_75_mixtral_22b'\n",
    "\n",
    "data_haiku_vision = pd.read_csv(\"../data/Vision/results_claude-3-haiku-20240307.csv\")\n",
    "data_haiku_vision['analysis_type'] = 'haiku_vision_allpages'\n",
    "data_sonnet_vision = pd.read_csv(\"../data/Vision/results_claude-3-5-sonnet-20240620.csv\")\n",
    "data_sonnet_vision['analysis_type'] = 'sonnet_vision_allpages'\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "all_data = pd.concat([\n",
    "    data_sonnet_fullcontext, data_haiku_fullcontext, data_opus_fullcontext,\n",
    "    data_haiku, data_sonnet, data_mixtral_7b, data_mixtral_22b,\n",
    "    data_haiku_25, data_haiku_50, data_haiku_75,\n",
    "    data_sonnet_25, data_sonnet_50, data_sonnet_75,\n",
    "    data_mixtral_7b_25, data_mixtral_7b_50, data_mixtral_7b_75,\n",
    "    data_mixtral_22b_25, data_mixtral_22b_50, data_mixtral_22b_75, data_haiku_vision, data_sonnet_vision\n",
    "])\n",
    "\n",
    "# Remove the specified columns\n",
    "columns_to_remove = ['Unnamed: 0.10', 'Unnamed: 0.9', 'Unnamed: 0.8', 'Unnamed: 0.7',\n",
    "                     'Unnamed: 0.6', 'Unnamed: 0.5', 'Unnamed: 0.4', 'Unnamed: 0.3',\n",
    "                     'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0']\n",
    "\n",
    "all_data = all_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "df = all_data.copy()\n",
    "\n",
    "# all_data.to_csv(\"../data/output/all_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "In the previous chapter of this series, we explored the application of large language models (LLMs) for structured information extraction from wrongful conviction case files using traditional retrieval augmented generation (RAG). However, recent advancements in LLM technology have necessitated a re-evaluation of our information extraction pipeline. Models like Gemini 1.5 Pro with its one million token context window and Claude 3 with a 200k context window now allow entire documents to fit within a single context window, potentially eliminating the need for retrieving specific document pages. Furthermore, the emergence of cost-effective yet high-performing models like Claude Haiku has transformed our methodology. Unlike our initial evaluations, it is now feasible to iterate over every single page in a document, rather than attempting to extract only the most relevant pieces for analysis. This shift allows for a more comprehensive examination of the entire document, potentially uncovering insights that might have been missed in a more selective approach.\n",
    "\n",
    "This follow-up chapter aims to reconsider the fundamentals of our information extraction pipeline and explore the impact of these larger models on our research. Our approach—evaluating LLMs in legal research by focusing on entity extraction—aligns with recent computational law research suggesting that AI might be more effective in narrow, well-defined legal applications [1]. By concentrating on the specific task of identifying police officers in misconduct documents, we can assess LLM performance in a constrained legal context that is more amenable to large-scale evaluation due to its relative simplicity. This contrasts with the broader, more complex tasks attempted by generative legal research tools like Lexis+ AI and Casetext, which recent studies have shown to be prone to high rates of hallucination [2]. While our approach may still produce false positives, entity extraction tasks are generally less susceptible to the negative effects of hallucination, as these errors can often be identified and mitigated through careful prompt engineering. This focused approach allows us to develop techniques that can potentially extend to other entities (e.g., witnesses, victims, locations, evidence, legal precedents) and legal document types, while providing a more robust framework for assessing and improving AI performance in legal applications.\n",
    "\n",
    "In the following sections, we present our evaluations of various entity extraction techniques using both proprietary Claude models and the open-source Mixtral model, which can be deployed on private endpoints for sensitive documents. Our analysis compares different approaches, including full-context processing, named entity recognition (NER) based methods, and page-by-page analysis, to determine the most effective and efficient strategies for entity extraction in legal documents.\n",
    "\n",
    "## Evaluations\n",
    "\n",
    "We conducted a comparative analysis of entity extraction techniques using both proprietary Claude models and the open-source Mixtral model.\n",
    "We evaluated three distinct extraction techniques:\n",
    "\n",
    "1. **All Context**: This approach processes the entire document at once, utilizing the full context window capabilities of Claude 3 Sonnet, Claude 3 Haiku, and Claude 3 Opus.\n",
    "\n",
    "2. **All Pages**: This technique iterates over each page in the document sequentially. We applied this method using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants).\n",
    "\n",
    "3. **Named Entity Recognition (NER) Based**: This method preprocesses the document to identify pages with the highest concentration of entities, then analyzes these high-density areas. We tested this approach with varying percentages (25%, 50%, and 75%) of the most entity-rich pages using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_count</th>\n",
       "      <th>total_ground_truth</th>\n",
       "      <th>percentage_matched</th>\n",
       "      <th>matched_names</th>\n",
       "      <th>unmatched_names</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f_beta_score</th>\n",
       "      <th>token_count</th>\n",
       "      <th>filename</th>\n",
       "      <th>filetype</th>\n",
       "      <th>model</th>\n",
       "      <th>unique_entity_count</th>\n",
       "      <th>file_name</th>\n",
       "      <th>analysis_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>{'t. sauvage', 'gerald ursin', 'j. treadway', ...</td>\n",
       "      <td>{'jefferson', 'patricia f. daniels', 'thomas s...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5871</td>\n",
       "      <td>1. Supplemental Report.json</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>11</td>\n",
       "      <td>1. Supplemental Report.json.csv</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>{'barrett morton'}</td>\n",
       "      <td>{'kenneth leary', 'garner'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>41487</td>\n",
       "      <td>01 Trial transcript.json</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>01 Trial transcript.json.csv</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>12.121212</td>\n",
       "      <td>{'martin venezia', 'james dneps', 'pat roche',...</td>\n",
       "      <td>{'wayne cooper', 'samuels', 'norville orazio (...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>102827</td>\n",
       "      <td>Adams_Exhibit Volumes FILED.json</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>33</td>\n",
       "      <td>Adams_Exhibit Volumes FILED.json.csv</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>{'martin venezia', 'frank ruiz', 'jerry ursin'...</td>\n",
       "      <td>{'little'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>22254</td>\n",
       "      <td>(C) Det. Martin Venezia Testimony - Trial One....</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>6</td>\n",
       "      <td>(C) Det. Martin Venezia Testimony - Trial One....</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>{'marco nuzzolillo', 'ralph peperone', 'larry ...</td>\n",
       "      <td>{'masson', 'o’neal', 'viera', 'david dussel', ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>26172</td>\n",
       "      <td>Alexander_Betty Neff Police Reports including ...</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>13</td>\n",
       "      <td>Alexander_Betty Neff Police Reports including ...</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matched_count  total_ground_truth  percentage_matched  \\\n",
       "0              6                  11           54.545455   \n",
       "1              1                   3           33.333333   \n",
       "2              4                  33           12.121212   \n",
       "3              5                   6           83.333333   \n",
       "4              3                  13           23.076923   \n",
       "\n",
       "                                       matched_names  \\\n",
       "0  {'t. sauvage', 'gerald ursin', 'j. treadway', ...   \n",
       "1                                 {'barrett morton'}   \n",
       "2  {'martin venezia', 'james dneps', 'pat roche',...   \n",
       "3  {'martin venezia', 'frank ruiz', 'jerry ursin'...   \n",
       "4  {'marco nuzzolillo', 'ralph peperone', 'larry ...   \n",
       "\n",
       "                                     unmatched_names  true_positives  \\\n",
       "0  {'jefferson', 'patricia f. daniels', 'thomas s...               6   \n",
       "1                        {'kenneth leary', 'garner'}               1   \n",
       "2  {'wayne cooper', 'samuels', 'norville orazio (...               4   \n",
       "3                                         {'little'}               5   \n",
       "4  {'masson', 'o’neal', 'viera', 'david dussel', ...               3   \n",
       "\n",
       "   false_positives  precision    recall  f1_score  f_beta_score  token_count  \\\n",
       "0                0   1.000000  0.545455  0.705882      0.600000         5871   \n",
       "1                0   1.000000  0.333333  0.500000      0.384615        41487   \n",
       "2                3   0.571429  0.121212  0.200000      0.143885       102827   \n",
       "3                0   1.000000  0.833333  0.909091      0.862069        22254   \n",
       "4                3   0.500000  0.230769  0.315789      0.258621        26172   \n",
       "\n",
       "                                            filename    filetype  \\\n",
       "0                        1. Supplemental Report.json      report   \n",
       "1                           01 Trial transcript.json  transcript   \n",
       "2                   Adams_Exhibit Volumes FILED.json  transcript   \n",
       "3  (C) Det. Martin Venezia Testimony - Trial One....  transcript   \n",
       "4  Alexander_Betty Neff Police Reports including ...      report   \n",
       "\n",
       "                        model  unique_entity_count  \\\n",
       "0  claude-3-5-sonnet-20240620                   11   \n",
       "1  claude-3-5-sonnet-20240620                    3   \n",
       "2  claude-3-5-sonnet-20240620                   33   \n",
       "3  claude-3-5-sonnet-20240620                    6   \n",
       "4  claude-3-5-sonnet-20240620                   13   \n",
       "\n",
       "                                           file_name       analysis_type  \n",
       "0                    1. Supplemental Report.json.csv  fullcontext_sonnet  \n",
       "1                       01 Trial transcript.json.csv  fullcontext_sonnet  \n",
       "2               Adams_Exhibit Volumes FILED.json.csv  fullcontext_sonnet  \n",
       "3  (C) Det. Martin Venezia Testimony - Trial One....  fullcontext_sonnet  \n",
       "4  Alexander_Betty Neff Police Reports including ...  fullcontext_sonnet  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall Scores\n",
    "\n",
    "1. **All Pages Approach**:\n",
    "   - Claude 3.5 Sonnet performed best, with a score of 0.928427.\n",
    "   - Claude 3 Haiku followed closely with 0.915879.\n",
    "   - Mixtral models, while scoring lower, showed promising results:\n",
    "     - Mixtral 7B achieved 0.757376\n",
    "     - Mixtral 22B scored 0.691705\n",
    "\n",
    "2. **NER-Based Approach**:\n",
    "   - A clear trend emerged: performance improved as the percentage of analyzed pages increased:\n",
    "     - For Claude 3.5 Sonnet:\n",
    "       - 25% of pages: 0.757902\n",
    "       - 50% of pages: 0.875900\n",
    "       - 75% of pages: 0.917286\n",
    "     - Similarly for Claude 3 Haiku:\n",
    "       - 25% of pages: 0.707133\n",
    "       - 50% of pages: 0.824132\n",
    "       - 75% of pages: 0.857834\n",
    "   - Mixtral models followed the same pattern, though with lower overall scores:\n",
    "     - Mixtral 7B:\n",
    "       - 25% of pages: 0.552486\n",
    "       - 50% of pages: 0.692082\n",
    "       - 75% of pages: 0.713728\n",
    "     - Mixtral 22B:\n",
    "       - 25% of pages: 0.576426\n",
    "       - 50% of pages: 0.660638\n",
    "       - 75% of pages: 0.681340\n",
    "   \n",
    "3. **Full Context Approach**:\n",
    "   - This method yielded the lowest scores across all models:\n",
    "     - Claude 3 Haiku: 0.565231\n",
    "     - Claude 3 Opus: 0.632520\n",
    "     - Claude 3.5 Sonnet: 0.478544\n",
    "\n",
    "**Note on Vision Models:**\n",
    "For the purposes of testing, we also performed this analysis using vision-capable models. The scores for the all pages approach were:\n",
    "- Claude 3.5 Sonnet (Vision): 0.668353\n",
    "- Claude 3 Haiku (Vision): 0.653080\n",
    "\n",
    "These preliminary results suggest potential for vision models in document analysis tasks. Future research will focus more extensively on leveraging and optimizing vision models for entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f_beta_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allpages_sonnet</th>\n",
       "      <td>0.488414</td>\n",
       "      <td>0.928427</td>\n",
       "      <td>0.612417</td>\n",
       "      <td>0.753287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_sonnet</th>\n",
       "      <td>0.510440</td>\n",
       "      <td>0.917286</td>\n",
       "      <td>0.627615</td>\n",
       "      <td>0.757049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_haiku</th>\n",
       "      <td>0.293650</td>\n",
       "      <td>0.915879</td>\n",
       "      <td>0.419130</td>\n",
       "      <td>0.592581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_sonnet</th>\n",
       "      <td>0.537045</td>\n",
       "      <td>0.875900</td>\n",
       "      <td>0.637609</td>\n",
       "      <td>0.746241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_haiku</th>\n",
       "      <td>0.320703</td>\n",
       "      <td>0.857834</td>\n",
       "      <td>0.434793</td>\n",
       "      <td>0.586152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_haiku</th>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.824132</td>\n",
       "      <td>0.459179</td>\n",
       "      <td>0.596810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_sonnet</th>\n",
       "      <td>0.584956</td>\n",
       "      <td>0.757902</td>\n",
       "      <td>0.627014</td>\n",
       "      <td>0.687342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_mixtral_7b</th>\n",
       "      <td>0.179858</td>\n",
       "      <td>0.757376</td>\n",
       "      <td>0.275302</td>\n",
       "      <td>0.419564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_mixtral_7b</th>\n",
       "      <td>0.210210</td>\n",
       "      <td>0.713728</td>\n",
       "      <td>0.302370</td>\n",
       "      <td>0.435764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_haiku</th>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.707133</td>\n",
       "      <td>0.503123</td>\n",
       "      <td>0.586464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_mixtral_7b</th>\n",
       "      <td>0.254591</td>\n",
       "      <td>0.692082</td>\n",
       "      <td>0.339695</td>\n",
       "      <td>0.458171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_mixtral_22b</th>\n",
       "      <td>0.256271</td>\n",
       "      <td>0.691705</td>\n",
       "      <td>0.344113</td>\n",
       "      <td>0.462193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_mixtral_22b</th>\n",
       "      <td>0.314018</td>\n",
       "      <td>0.681340</td>\n",
       "      <td>0.401579</td>\n",
       "      <td>0.510346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnet_vision_allpages</th>\n",
       "      <td>0.454749</td>\n",
       "      <td>0.668353</td>\n",
       "      <td>0.505577</td>\n",
       "      <td>0.574669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_mixtral_22b</th>\n",
       "      <td>0.350529</td>\n",
       "      <td>0.660638</td>\n",
       "      <td>0.426856</td>\n",
       "      <td>0.520896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haiku_vision_allpages</th>\n",
       "      <td>0.370203</td>\n",
       "      <td>0.653080</td>\n",
       "      <td>0.449729</td>\n",
       "      <td>0.538895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_opus</th>\n",
       "      <td>0.785303</td>\n",
       "      <td>0.632520</td>\n",
       "      <td>0.686736</td>\n",
       "      <td>0.650934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_mixtral_22b</th>\n",
       "      <td>0.455386</td>\n",
       "      <td>0.576426</td>\n",
       "      <td>0.466610</td>\n",
       "      <td>0.511645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_haiku</th>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.565231</td>\n",
       "      <td>0.621112</td>\n",
       "      <td>0.584355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_mixtral_7b</th>\n",
       "      <td>0.310901</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.367270</td>\n",
       "      <td>0.440888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_sonnet</th>\n",
       "      <td>0.824666</td>\n",
       "      <td>0.478544</td>\n",
       "      <td>0.577609</td>\n",
       "      <td>0.511290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1_score  f_beta_score\n",
       "analysis_type                                                      \n",
       "allpages_sonnet          0.488414  0.928427  0.612417      0.753287\n",
       "ner_75_sonnet            0.510440  0.917286  0.627615      0.757049\n",
       "allpages_haiku           0.293650  0.915879  0.419130      0.592581\n",
       "ner_50_sonnet            0.537045  0.875900  0.637609      0.746241\n",
       "ner_75_haiku             0.320703  0.857834  0.434793      0.586152\n",
       "ner_50_haiku             0.353012  0.824132  0.459179      0.596810\n",
       "ner_25_sonnet            0.584956  0.757902  0.627014      0.687342\n",
       "allpages_mixtral_7b      0.179858  0.757376  0.275302      0.419564\n",
       "ner_75_mixtral_7b        0.210210  0.713728  0.302370      0.435764\n",
       "ner_25_haiku             0.451221  0.707133  0.503123      0.586464\n",
       "ner_50_mixtral_7b        0.254591  0.692082  0.339695      0.458171\n",
       "allpages_mixtral_22b     0.256271  0.691705  0.344113      0.462193\n",
       "ner_75_mixtral_22b       0.314018  0.681340  0.401579      0.510346\n",
       "sonnet_vision_allpages   0.454749  0.668353  0.505577      0.574669\n",
       "ner_50_mixtral_22b       0.350529  0.660638  0.426856      0.520896\n",
       "haiku_vision_allpages    0.370203  0.653080  0.449729      0.538895\n",
       "fullcontext_opus         0.785303  0.632520  0.686736      0.650934\n",
       "ner_25_mixtral_22b       0.455386  0.576426  0.466610      0.511645\n",
       "fullcontext_haiku        0.724370  0.565231  0.621112      0.584355\n",
       "ner_25_mixtral_7b        0.310901  0.552486  0.367270      0.440888\n",
       "fullcontext_sonnet       0.824666  0.478544  0.577609      0.511290"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = all_data.groupby(\"analysis_type\").agg({\n",
    "    \"precision\": \"mean\",\n",
    "    \"recall\": \"mean\",\n",
    "    \"f1_score\": \"mean\",\n",
    "    \"f_beta_score\": \"mean\"\n",
    "}).sort_values(\"recall\", ascending=False)\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Precision and F1 Scores\n",
    "\n",
    "While our analysis shows high recall scores across the different models with the all pages method, it's important to note that the F1 scores are relatively low due to poor precision (high false positive rates). However, this is not a significant concern in our context due to our prompting strategy.\n",
    "\n",
    "Our approach requires the model to provide a comprehensive profile of each identified individual, making it easy to filter out false positives. Here's an example of our prompting template:\n",
    "\n",
    "```python\n",
    "template = \"\"\"\n",
    "    As an AI assistant, my role is to meticulously analyze criminal justice documents and extract information about law enforcement personnel.\n",
    "\n",
    "    Query: {question}\n",
    "\n",
    "    Documents: {docs}\n",
    "\n",
    "    The response will contain:\n",
    "\n",
    "    1) The name of a law enforcement personnel. Law enforcement personnel can be identified by searching for these name prefixes: ofcs., officers, sergeants, sgts., lieutenants, lts., captains, cpts., commanders, sheriffs, deputies, dtys., detectives, dets., inspectors, technicians, analysts, coroners.\n",
    "\n",
    "    Please prefix the name with \"Officer Name: \".\n",
    "    For example, \"Officer Name: John Smith\".\n",
    "\n",
    "    2) If available, provide an in-depth description of the context of their mention.\n",
    "    If the context induces ambiguity regarding the individual's employment in law enforcement, please make this clear in your response.\n",
    "\n",
    "    Please prefix this information with \"Officer Context: \".\n",
    "\n",
    "    3) Review the context to discern the role of the officer. For example, Lead Detective (Homicide Division), Supervising Officer (Crime Lab), Detective, Officer on Scene, Arresting Officer, Crime Lab Analyst\n",
    "\n",
    "    Please prefix this information with \"Officer Role: \"\n",
    "    For example, \"Officer Role: Lead Detective\"\n",
    "\n",
    "    The full response should follow the format below, with no prefixes such as 1., 2., 3., a., b., c., etc.:\n",
    "\n",
    "    Officer Name: John Smith\n",
    "    Officer Context: Mentioned as someone who was present during a search, along with other detectives from different units.\n",
    "    Officer Role: Patrol Officer\n",
    "\n",
    "    Officer Name:\n",
    "    Officer Context:\n",
    "    Officer Role:\n",
    "\n",
    "    - Do not include any prefixes\n",
    "    - Only derive responses from factual information found within the police reports.\n",
    "    - If the context of an identified person's mention is not clear in the report, provide their name and note that the context is not specified.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "This prompting strategy effectively addresses the challenge of over-extraction while maintaining high recall. Our prompt instructs the model to provide an \"in-depth description of the context of their mention\" and to \"discern the role of the officer,\" which helps in accurately categorizing individuals. Consider this output example:\n",
    "\n",
    "Officer Name: Thomas Burns\n",
    "Officer Context: Mentioned in the obituaries as the father of Jamie Burns, who was the victim in the case.\n",
    "Officer Role: Not a law enforcement officer\n",
    "\n",
    "Here, the model initially extracted Thomas Burns as a potential law enforcement officer, demonstrating the tendency to over-extract names. However, our prompting technique mitigates this issue by requiring additional context. By leveraging our prompt's instruction to \"only derive responses from factual information found within the police reports\" and to make it clear \"if the context induces ambiguity regarding the individual's employment in law enforcement,\" we enable the model to provide crucial contextual information. This allows us to easily identify and filter out non-law enforcement personnel in post-processing.\n",
    "\n",
    "The seemingly low F1 scores due to poor precision rates are less concerning in practice because our prompting strategy effectively addresses over-extraction and misclassification. By requiring clear context for each identified individual and following the structured format specified in our prompt (Officer Name, Officer Context, Officer Role), we facilitate easy post-processing and filtering of results. This ensures that our final output maintains high recall while significantly improving precision, accurately capturing law enforcement personnel mentions and providing a clear mechanism to identify and remove non-officers from the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Insight\n",
    "\n",
    "Based on the results, the all pages analysis approach consistently outperformed other methods across all tested models. The full context approach, despite its theoretical potential, demonstrated significant limitations in practice. This is likely due to the many known issues associated with use of the full context window [3], including degraded retrieval performance with increasing context length, impaired reasoning capabilities over multiple facts, and susceptibility to information overload. Given that the NER-based approaches are essentially derivatives of the all pages method, and considering the superior performance of the all pages models, the rest of this post will focus exclusively on this most effective approach.\n",
    "\n",
    "While the Mixtral models scored lower than their Claude counterparts, their performance is notably impressive considering their unique advantages. The Mixtral 7B model achieved a score of 0.786638, and the larger Mixtral 22B scored 0.729260 in the all pages approach. These scores are particularly significant given that Mixtral models can be run locally on consumer hardware, eliminating the need for cloud-based API calls. This local execution capability not only makes them cost-effective - as they can be used without incurring API fees - but also opens up possibilities for processing sensitive or confidential data that cannot leave the user's computer due to privacy or security concerns. The ability to achieve such performative results with these additional benefits makes Mixtral models a compelling option for certain use cases, especially when considering the trade-off between performance and data privacy.\n",
    "\n",
    "While the Mixtral models offer unique advantages in terms of local execution and data privacy, the Claude family were even more performative in entity recognition tasks. In particular, Claude 3 Haiku achieved an overall recall score of 0.915 (or 215 out of 232 entities correctly identified). To put this performance into perspective, let's examine a specific case study involving a 185-page document. Claude 3 Haiku correctly identified 32 out of 33 entities (police officers) in a 185-page transcript document. The total cost for this operation using Haiku was just $0.1275, significantly lower than its counterparts in the Claude 3 family. For comparison, the same task would have cost $1.53 with Claude 3.5 Sonnet and $7.65 with Claude 3 Opus.\n",
    "\n",
    "To put this in perspective, a human performing the same task would take approximately 5 hours, assuming an average reading speed of 225 words per minute and additional time for entity identification. At a rate of $30 per hour, the human labor cost would be around $150. This stark contrast—5 hours and $150 for a human versus near-instantaneous processing and $0.1275 for Claude 3 Haiku—underscores the remarkable efficiency and cost-effectiveness of AI in such tasks. While the dollar cost comparison is useful for illustrating the advantages of AI models like Haiku and Mixtral, the true value lies in the dramatic reallocation of human time and effort away from menial tasks. The AI not only completes the job in seconds at a fraction of the cost but also maintains high accuracy, freeing up individuals to focus on more creative and complex activities. \n",
    "\n",
    "# Additional Insights\n",
    "\n",
    "Building upon these key insights, we sought to deepen our understanding of the factors contributing to the performance variations between Claude and Mixtral models in the all pages method. Our additional analysis focuses on two aspects:\n",
    "\n",
    "1. Entity Complexity: An examination of how Claude and Mixtral models differ in handling single-word versus multi-word entities.\n",
    "2. Feature Importance: An evaluation of which input characteristics most significantly influence the performance of Claude and Mixtral models. \n",
    "\n",
    "Entity Complexity \n",
    "\n",
    "1. **Claude Models Performance**:\n",
    "   - Claude 3.5 Sonnet showed the best overall performance, with the lowest percentage of unmatched single-word entities (18.18%) and a very low percentage of unmatched multi-word entities (5.08%).\n",
    "   - Claude 3 Haiku performed similarly well, with slightly higher unmatched percentages (21.82% for single-word and 4.52% for multi-word entities).\n",
    "\n",
    "2. **Mixtral Models Performance**:\n",
    "   - Both Mixtral models showed higher percentages of unmatched entities compared to the Claude models.\n",
    "   - Mixtral 7B performed better than Mixtral 22B, particularly in multi-word entity extraction.\n",
    "   - Mixtral 22B had the highest percentage of unmatched entities for both single-word (36.36%) and multi-word (22.60%) categories.\n",
    "\n",
    "3. **Single-Word vs. Multi-Word Entity Extraction**:\n",
    "   - All models generally performed better in extracting multi-word entities compared to single-word entities, as evidenced by the lower percentage of unmatched multi-word entities across all models.\n",
    "   - This trend was particularly pronounced in the Claude models, which showed a significant performance gap between single-word and multi-word entity extraction.\n",
    "\n",
    "4. **Model Size and Performance**:\n",
    "   - Interestingly, the larger Mixtral 22B model underperformed compared to its smaller 7B counterpart. This suggests that larger model size doesn't always correlate with better performance in specific tasks like entity extraction.\n",
    "   - In contrast, the more advanced Claude 3.5 Sonnet outperformed Claude 3 Haiku, albeit by a small margin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis Type</th>\n",
       "      <th>total_single_word_entities</th>\n",
       "      <th>total_multi_word_entities</th>\n",
       "      <th>unmatched_single_word_entities</th>\n",
       "      <th>unmatched_multi_word_entities</th>\n",
       "      <th>pct_unmatched_single_word</th>\n",
       "      <th>pct_unmatched_multi_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.389831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>22.598870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>29.090909</td>\n",
       "      <td>15.819209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>5.084746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>haiku_vision_allpages</td>\n",
       "      <td>54</td>\n",
       "      <td>168</td>\n",
       "      <td>22</td>\n",
       "      <td>55</td>\n",
       "      <td>40.740741</td>\n",
       "      <td>32.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sonnet_vision_allpages</td>\n",
       "      <td>54</td>\n",
       "      <td>168</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>32.738095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Analysis Type  total_single_word_entities  \\\n",
       "0           allpages_haiku                          55   \n",
       "1     allpages_mixtral_22b                          55   \n",
       "2      allpages_mixtral_7b                          55   \n",
       "3          allpages_sonnet                          55   \n",
       "7    haiku_vision_allpages                          54   \n",
       "20  sonnet_vision_allpages                          54   \n",
       "\n",
       "    total_multi_word_entities  unmatched_single_word_entities  \\\n",
       "0                         177                              11   \n",
       "1                         177                              20   \n",
       "2                         177                              16   \n",
       "3                         177                              10   \n",
       "7                         168                              22   \n",
       "20                        168                              20   \n",
       "\n",
       "    unmatched_multi_word_entities  pct_unmatched_single_word  \\\n",
       "0                               6                  20.000000   \n",
       "1                              40                  36.363636   \n",
       "2                              28                  29.090909   \n",
       "3                               9                  18.181818   \n",
       "7                              55                  40.740741   \n",
       "20                             55                  37.037037   \n",
       "\n",
       "    pct_unmatched_multi_word  \n",
       "0                   3.389831  \n",
       "1                  22.598870  \n",
       "2                  15.819209  \n",
       "3                   5.084746  \n",
       "7                  32.738095  \n",
       "20                 32.738095  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_entity_characteristics(df):\n",
    "    results = []\n",
    "    \n",
    "    for analysis_type, group in df.groupby('analysis_type'):\n",
    "        all_entities = []\n",
    "        matched_entities = []\n",
    "        unmatched_entities = []\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            matched = set(literal_eval(row['matched_names']))\n",
    "            unmatched = set(literal_eval(row['unmatched_names']))\n",
    "            all_entities.extend(matched.union(unmatched))\n",
    "            matched_entities.extend(matched)\n",
    "            unmatched_entities.extend(unmatched)\n",
    "        \n",
    "        def categorize_entities(entities):\n",
    "            single_word = [e for e in entities if len(e.split()) == 1]\n",
    "            multi_word = [e for e in entities if len(e.split()) > 1]\n",
    "            return single_word, multi_word\n",
    "        \n",
    "        all_single, all_multi = categorize_entities(all_entities)\n",
    "        matched_single, matched_multi = categorize_entities(matched_entities)\n",
    "        \n",
    "        total_single = len(all_single)\n",
    "        total_multi = len(all_multi)\n",
    "        \n",
    "        unmatched_single = total_single - len(matched_single)\n",
    "        unmatched_multi = total_multi - len(matched_multi)\n",
    "        \n",
    "        pct_unmatched_single = (unmatched_single / total_single) * 100 if total_single > 0 else 0\n",
    "        pct_unmatched_multi = (unmatched_multi / total_multi) * 100 if total_multi > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Analysis Type': analysis_type,\n",
    "            'total_single_word_entities': total_single,\n",
    "            'total_multi_word_entities': total_multi,\n",
    "            'unmatched_single_word_entities': unmatched_single,\n",
    "            'unmatched_multi_word_entities': unmatched_multi,\n",
    "            'pct_unmatched_single_word': pct_unmatched_single,\n",
    "            'pct_unmatched_multi_word': pct_unmatched_multi\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Assuming all_data is your input DataFrame\n",
    "compare_df = analyze_entity_characteristics(df)\n",
    "compare_df.to_csv(\"../data/output/compare.csv\")\n",
    "\n",
    "compare_df = compare_df[compare_df[\"Analysis Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "1. Haiku Model Analysis Summary\n",
    "For report documents, the Haiku model has a high R² score of 0.8812, indicating reliable predictions. The most important features are average entity length (0.4420) and percent single-word entities (0.3603), both above the absolute threshold of 0.333 and significantly contributing to the model's performance. Percent multi-word entities (0.1976) is below the threshold and therefore considered less important. For transcript documents, the low R² score (0.3643) suggests that the feature importances may be less reliable, so further model improvement is necessary before drawing conclusions about feature significance.\n",
    "\n",
    "2. Sonnet Model Analysis Summary\n",
    "For report documents, the Sonnet model has a high R² score of 0.8774, indicating reliable predictions. The most important feature is average entity length (0.4652), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Percent single-word entities (0.3112) and percent multi-word entities (0.2236) are below the threshold and therefore considered less important. For transcript documents, the high R² score (0.7261) indicates good model performance. Here, the feature importances are balanced but slightly below the threshold, with average entity length (0.3459), percent multi-word entities (0.3298), and percent single-word entities (0.3242) all playing notable roles.\n",
    "\n",
    "3. Mixtral 8b Model Analysis Summary\n",
    "For report documents, the Mixtral 8b model has a high R² score of 0.8349, indicating reliable predictions. The most important feature is percent multi-word entities (0.4079), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Average entity length (0.2924) and percent single-word entities (0.2997) are below the threshold and therefore considered less important. For transcript documents, the moderate R² score (0.6506) suggests good model performance. Here, the feature importances are balanced but slightly below the threshold, with average entity length (0.3250), percent multi-word entities (0.3425), and percent single-word entities (0.3325) all playing notable roles.\n",
    "\n",
    "4. Mixtral 22b Model Analysis Summary\n",
    "For report documents, the Mixtral 22b model has a high R² score of 0.8149, indicating reliable predictions. The most important feature is average entity length (0.4291), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Percent single-word entities (0.3287) and percent multi-word entities (0.2423) are below the threshold and therefore considered less important. For transcript documents, the low R² score (0.3935) suggests that the feature importances may be less reliable, so further model improvement is necessary before drawing conclusions about feature significance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Feature Importances (Excluding Low R² Scores)\n",
      "Average Entity Length: 0.3058\n",
      "Percent Multi-Word Entities: 0.2955\n",
      "Percent Single-Word Entities: 0.3987\n",
      "\n",
      "Absolute Threshold for Importance: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis_Type</th>\n",
       "      <th>Document_Type</th>\n",
       "      <th>NER_Percentage</th>\n",
       "      <th>Average_F_Beta_Score</th>\n",
       "      <th>Average_RMSE</th>\n",
       "      <th>Average_R2</th>\n",
       "      <th>Average_Entities_Per_Token</th>\n",
       "      <th>Average_Entity_Length</th>\n",
       "      <th>Percent_Multi_Word_Entities</th>\n",
       "      <th>avg_entity_length</th>\n",
       "      <th>pct_multi_word_entities</th>\n",
       "      <th>pct_single_word_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.678744</td>\n",
       "      <td>0.055453</td>\n",
       "      <td>0.912587</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.280603</td>\n",
       "      <td>0.249036</td>\n",
       "      <td>0.470360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.496845</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.854255</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.348546</td>\n",
       "      <td>0.317832</td>\n",
       "      <td>0.333622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>0.055804</td>\n",
       "      <td>0.856801</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.330407</td>\n",
       "      <td>0.349754</td>\n",
       "      <td>0.319839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.315893</td>\n",
       "      <td>0.083897</td>\n",
       "      <td>0.738212</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.238021</td>\n",
       "      <td>0.212650</td>\n",
       "      <td>0.549329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.857118</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.245634</td>\n",
       "      <td>0.300830</td>\n",
       "      <td>0.453536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.292112</td>\n",
       "      <td>0.055580</td>\n",
       "      <td>0.838361</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.346439</td>\n",
       "      <td>0.302857</td>\n",
       "      <td>0.350705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.883384</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.325290</td>\n",
       "      <td>0.306120</td>\n",
       "      <td>0.368591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.727645</td>\n",
       "      <td>0.041126</td>\n",
       "      <td>0.871706</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.364919</td>\n",
       "      <td>0.301955</td>\n",
       "      <td>0.333126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>haiku_vision_allpages</td>\n",
       "      <td>pdf</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.538895</td>\n",
       "      <td>0.077371</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.744224</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.283959</td>\n",
       "      <td>0.303235</td>\n",
       "      <td>0.412806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sonnet_vision_allpages</td>\n",
       "      <td>pdf</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.574669</td>\n",
       "      <td>0.088978</td>\n",
       "      <td>0.819344</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.744224</td>\n",
       "      <td>0.730756</td>\n",
       "      <td>0.294085</td>\n",
       "      <td>0.310419</td>\n",
       "      <td>0.395496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Analysis_Type Document_Type NER_Percentage  Average_F_Beta_Score  \\\n",
       "0           allpages_haiku        report            N/A              0.678744   \n",
       "1           allpages_haiku    transcript            N/A              0.496845   \n",
       "2     allpages_mixtral_22b        report            N/A              0.593864   \n",
       "3     allpages_mixtral_22b    transcript            N/A              0.315893   \n",
       "4      allpages_mixtral_7b        report            N/A              0.534272   \n",
       "5      allpages_mixtral_7b    transcript            N/A              0.292112   \n",
       "6          allpages_sonnet        report            N/A              0.776365   \n",
       "7          allpages_sonnet    transcript            N/A              0.727645   \n",
       "14   haiku_vision_allpages           pdf            N/A              0.538895   \n",
       "39  sonnet_vision_allpages           pdf            N/A              0.574669   \n",
       "\n",
       "    Average_RMSE  Average_R2  Average_Entities_Per_Token  \\\n",
       "0       0.055453    0.912587                    0.001355   \n",
       "1       0.044783    0.854255                    0.000444   \n",
       "2       0.055804    0.856801                    0.001355   \n",
       "3       0.083897    0.738212                    0.000444   \n",
       "4       0.064669    0.857118                    0.001355   \n",
       "5       0.055580    0.838361                    0.000444   \n",
       "6       0.047625    0.883384                    0.001355   \n",
       "7       0.041126    0.871706                    0.000444   \n",
       "14      0.077371    0.865132                         inf   \n",
       "39      0.088978    0.819344                         inf   \n",
       "\n",
       "    Average_Entity_Length  Percent_Multi_Word_Entities  avg_entity_length  \\\n",
       "0                1.797343                     0.779161           0.280603   \n",
       "1                1.702510                     0.695776           0.348546   \n",
       "2                1.797343                     0.779161           0.330407   \n",
       "3                1.702510                     0.695776           0.238021   \n",
       "4                1.797343                     0.779161           0.245634   \n",
       "5                1.702510                     0.695776           0.346439   \n",
       "6                1.797343                     0.779161           0.325290   \n",
       "7                1.702510                     0.695776           0.364919   \n",
       "14               1.744224                     0.730756           0.283959   \n",
       "39               1.744224                     0.730756           0.294085   \n",
       "\n",
       "    pct_multi_word_entities  pct_single_word_entities  \n",
       "0                  0.249036                  0.470360  \n",
       "1                  0.317832                  0.333622  \n",
       "2                  0.349754                  0.319839  \n",
       "3                  0.212650                  0.549329  \n",
       "4                  0.300830                  0.453536  \n",
       "5                  0.302857                  0.350705  \n",
       "6                  0.306120                  0.368591  \n",
       "7                  0.301955                  0.333126  \n",
       "14                 0.303235                  0.412806  \n",
       "39                 0.310419                  0.395496  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_entity_complexity_features(row):\n",
    "    matched = set(literal_eval(row['matched_names']))\n",
    "    unmatched = set(literal_eval(row['unmatched_names']))\n",
    "    all_entities = matched.union(unmatched)\n",
    "    \n",
    "    if all_entities:\n",
    "        avg_entity_length = np.mean([len(entity.split()) for entity in all_entities])\n",
    "        pct_multi_word = sum(len(entity.split()) > 1 for entity in all_entities) / len(all_entities)\n",
    "        pct_single_word = sum(len(entity.split()) == 1 for entity in all_entities) / len(all_entities)\n",
    "    else:\n",
    "        avg_entity_length = 0\n",
    "        pct_multi_word = 0\n",
    "        pct_single_word = 0\n",
    "    \n",
    "    return pd.Series({\n",
    "        'avg_entity_length': avg_entity_length,\n",
    "        'pct_multi_word_entities': pct_multi_word,\n",
    "        'pct_single_word_entities': pct_single_word\n",
    "    })\n",
    "\n",
    "def analyze_data(data):\n",
    "    complexity_features = data.apply(calculate_entity_complexity_features, axis=1)\n",
    "    data = pd.concat([data, complexity_features], axis=1)\n",
    "    \n",
    "    data['entities_per_token'] = data['total_ground_truth'] / data['token_count']\n",
    "    \n",
    "    X = data[['avg_entity_length', 'pct_multi_word_entities', 'pct_single_word_entities']]\n",
    "    y = data['f_beta_score']\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    predictions = rf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    r2 = r2_score(y, predictions)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    feature_names = X.columns\n",
    "\n",
    "    feature_importances = {name: importance for name, importance in zip(feature_names, importances)}\n",
    "\n",
    "    return rmse, r2, feature_importances, data\n",
    "\n",
    "def process_data(all_data):\n",
    "    results = []\n",
    "    for analysis_type, group in all_data.groupby('analysis_type'):\n",
    "        if 'filetype' in group.columns:\n",
    "            doc_types = group['filetype'].unique()\n",
    "        else:\n",
    "            doc_types = ['combined']\n",
    "        \n",
    "        for doc_type in doc_types:\n",
    "            if doc_type != 'combined':\n",
    "                filtered_data = group[group['filetype'] == doc_type]\n",
    "            else:\n",
    "                filtered_data = group\n",
    "            \n",
    "            if not filtered_data.empty:\n",
    "                rmse, r2, feature_importances, updated_data = analyze_data(filtered_data)\n",
    "                result = {\n",
    "                    'Analysis_Type': analysis_type,\n",
    "                    'Document_Type': doc_type,\n",
    "                    'Average_F_Beta_Score': updated_data['f_beta_score'].mean(),\n",
    "                    'Average_RMSE': rmse,\n",
    "                    'Average_R2': r2,\n",
    "                    'Average_Entities_Per_Token': updated_data['entities_per_token'].mean(),\n",
    "                    'Average_Entity_Length': updated_data['avg_entity_length'].mean(),\n",
    "                    'Percent_Multi_Word_Entities': updated_data['pct_multi_word_entities'].mean(),\n",
    "                    **feature_importances\n",
    "                }\n",
    "                \n",
    "                # Extract NER percentage if it's an NER analysis type\n",
    "                if 'ner' in analysis_type:\n",
    "                    result['NER_Percentage'] = analysis_type.split('_')[1]\n",
    "                else:\n",
    "                    result['NER_Percentage'] = 'N/A'\n",
    "                \n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "results = process_data(all_data)\n",
    "results_df = pd.DataFrame(results)\n",
    "groupby_columns = ['Analysis_Type', 'Document_Type', 'NER_Percentage']\n",
    "grouped_results_df = results_df.groupby(groupby_columns).mean().reset_index()\n",
    "# grouped_results_df.to_csv(\"../data/output/grouped.csv\")\n",
    "grouped_results_df = grouped_results_df[grouped_results_df[\"Analysis_Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "\n",
    "def calculate_mean_feature_importances(grouped_results_df, r2_threshold=0.5):\n",
    "    valid_feature_importances = {\n",
    "        'Average Entity Length': [],\n",
    "        'Percent Multi-Word Entities': [],\n",
    "        'Percent Single-Word Entities': []\n",
    "    }\n",
    "\n",
    "    for index, row in grouped_results_df.iterrows():\n",
    "        if row['Average_R2'] >= r2_threshold:\n",
    "            valid_feature_importances['Average Entity Length'].append(row['avg_entity_length'])\n",
    "            valid_feature_importances['Percent Multi-Word Entities'].append(row['pct_multi_word_entities'])\n",
    "            valid_feature_importances['Percent Single-Word Entities'].append(row['pct_single_word_entities'])\n",
    "\n",
    "    valid_mean_feature_importances = {feature: sum(values) / len(values) for feature, values in valid_feature_importances.items()}\n",
    "\n",
    "    return valid_mean_feature_importances\n",
    "\n",
    "mean_feature_importances = calculate_mean_feature_importances(grouped_results_df)\n",
    "\n",
    "print(\"Mean Feature Importances (Excluding Low R² Scores)\")\n",
    "for feature, importance in mean_feature_importances.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "absolute_threshold = sum(mean_feature_importances.values()) / len(mean_feature_importances)\n",
    "print(f\"\\nAbsolute Threshold for Importance: {absolute_threshold:.4f}\")\n",
    "\n",
    "grouped_results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The performance of LLMs in entity extraction, despite not achieving perfect scores, highlights their potential to accelerate legal document analysis. While humans might face similar limitations in capturing all facts (i.e., a human might reasonably only extract 210 out of 230 entities from a 175-page document as well), they excel at identifying and elaborating on the most crucial information. LLMs, however, offer a unique advantage: they can rapidly process vast document corpora. Additionally, the tendency to miss entities can be mitigated through analyzing multiple associated documents. The key to leveraging LLMs truly lies in developing an iterative workflow that begins with broad entity extraction, followed by targeted, entity-specific analyses. By refining prompts based on initial findings, we can guide LLMs to focus on the most relevant information, effectively combining machine efficiency with human-like discernment. As we continue to refine this approach, the future of legal document analysis looks promising, with LLMs serving not as replacements for human expertise, but as powerful tools to augment and streamline the analytical process.\n",
    "\n",
    "## Future research \n",
    "\n",
    "Building on our exploration of entity string characteristics, future research will investigate the impact of officer titles on model performance in entity identification. Specifically, we aim to extract officer titles (not roles) based on prefixes and analyze how the presence of these titles in the text affects the models' ability to identify officers. This study will focus on developing reasoning metrics to quantify the relationship between title presence and entity recognition accuracy, potentially unveiling new insights into how contextual cues influence LLM performance in legal document analysis.\n",
    "\n",
    "---\n",
    "\n",
    "[1] Guha, N., et al. (2024). The Future of Computational Law. Cross-disciplinary Research in Computational Law (CRCL), 2(2). https://journalcrcl.org/crcl/article/view/62/28\n",
    "\n",
    "[2] https://arxiv.org/pdf/2405.20362\n",
    "\n",
    "[3] https://blog.langchain.dev/multi-needle-in-a-haystack/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
