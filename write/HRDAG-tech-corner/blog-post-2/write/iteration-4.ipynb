{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "Image(filename='../data/banner.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "In the previous chapter of this series, we explored the application of large language models (LLMs) for structured information extraction from wrongful conviction case files using traditional retrieval augmented generation (RAG). However, recent advancements in LLM technology have necessitated a re-evaluation of our information extraction pipeline. Models like Gemini 1.5 Pro with its one million token context window and Claude 3 with a 200k context window now allow entire documents to fit within a single context window, potentially eliminating the need for retrieving specific document pages. Furthermore, the emergence of cost-effective yet high-performing models like Claude Haiku has transformed our methodology. Unlike our initial evaluations, it is now feasible to iterate over every single page in a document, rather than attempting to extract only the most relevant pieces for analysis. This shift allows for a more comprehensive examination of the entire document, potentially uncovering insights that might have been missed in a more selective approach.\n",
    "\n",
    "This follow-up chapter aims to reconsider the fundamentals of our information extraction pipeline and explore the impact of these larger models on our research. Our approach—evaluating LLMs in legal research by focusing on entity extraction—aligns with recent computational law research suggesting that AI might be more effective in narrow, well-defined legal applications [1]. By concentrating on the specific task of identifying police officers in misconduct documents, we can assess LLM performance in a practical legal context while developing techniques that can extend to other entities (e.g., witnesses, victims, locations, evidence, legal precedents) and legal document types.\n",
    "\n",
    "In the following sections, we present our evaluations of various entity extraction techniques using both proprietary Claude models and the open-source Mixtral model, which can be deployed on private endpoints for sensitive documents. Our analysis compares different approaches, including full-context processing, named entity recognition (NER) based methods, and page-by-page analysis, to determine the most effective and efficient strategies for entity extraction in legal documents.\n",
    "\n",
    "## Evaluations\n",
    "\n",
    "We conducted a comparative analysis of entity extraction techniques using both proprietary Claude models and the open-source Mixtral model.\n",
    "We evaluated three distinct extraction techniques:\n",
    "\n",
    "1. **All Context**: This approach processes the entire document at once, utilizing the full context window capabilities of Claude 3 Sonnet, Claude 3 Haiku, and Claude 3 Opus.\n",
    "\n",
    "2. **All Pages**: This technique iterates over each page in the document sequentially. We applied this method using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants).\n",
    "\n",
    "3. **Named Entity Recognition (NER) Based**: This method preprocesses the document to identify pages with the highest concentration of entities, then analyzes these high-density areas. We tested this approach with varying percentages (25%, 50%, and 75%) of the most entity-rich pages using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants).\n",
    "\n",
    "### Results\n",
    "\n",
    "1. **All Pages Approach**:\n",
    "   - Claude 3.5 Sonnet performed best, with a score of 0.938840.\n",
    "   - Claude 3 Haiku followed closely with 0.912932.\n",
    "   - Mixtral models, while scoring lower, showed promising results:\n",
    "     - Mixtral 7B achieved 0.786638\n",
    "     - Mixtral 22B scored 0.729260\n",
    "   \n",
    "2. **NER-Based Approach**:\n",
    "   - A clear trend emerged: performance improved as the percentage of analyzed pages increased:\n",
    "     - For Claude 3.5 Sonnet:\n",
    "       - 25% of pages: 0.786434\n",
    "       - 50% of pages: 0.896382\n",
    "       - 75% of pages: 0.931097\n",
    "     - Similarly for Claude 3 Haiku:\n",
    "       - 25% of pages: 0.738128\n",
    "       - 50% of pages: 0.847949\n",
    "       - 75% of pages: 0.875217\n",
    "   - Mixtral models followed the same pattern, though with lower overall scores:\n",
    "     - Mixtral 7B:\n",
    "       - 25% of pages: 0.593477\n",
    "       - 50% of pages: 0.729663\n",
    "       - 75% of pages: 0.748019\n",
    "     - Mixtral 22B:\n",
    "       - 25% of pages: 0.616207\n",
    "       - 50% of pages: 0.701467\n",
    "       - 75% of pages: 0.716072\n",
    "   \n",
    "3. **Full Context Approach**:\n",
    "   - This method yielded the lowest scores across all models:\n",
    "     - Claude 3 Haiku: 0.607521\n",
    "     - Claude 3 Opus: 0.671461\n",
    "     - Claude 3.5 Sonnet: 0.520698\n",
    "\n",
    "### Insights\n",
    "\n",
    "Based on the results, the all pages analysis approach consistently outperformed other methods across all tested models. The full context approach, despite its theoretical potential, demonstrated significant limitations in practice. This is likely due to the many known issues associated with use of the full context window [2], including degraded retrieval performance with increasing context length, impaired reasoning capabilities over multiple facts, and susceptibility to information overload. Given that the NER-based approaches are essentially derivatives of the all pages method, and considering the superior performance of the all pages models, the rest of this post will focus exclusively on this most effective approach.\n",
    "\n",
    "While the Mixtral models scored lower than their Claude counterparts, their performance is notably impressive considering their unique advantages. The Mixtral 7B model achieved a score of 0.786638, and the larger Mixtral 22B scored 0.729260 in the all pages approach. These scores are particularly significant given that Mixtral models can be run locally on consumer hardware, eliminating the need for cloud-based API calls. This local execution capability not only makes them cost-effective - as they can be used without incurring API fees - but also opens up possibilities for processing sensitive or confidential data that cannot leave the user's computer due to privacy or security concerns. The ability to achieve such competitive results with these additional benefits makes Mixtral models a compelling option for certain use cases, especially when considering the trade-off between performance and data privacy.\n",
    "\n",
    "While the Mixtral models offer unique advantages in terms of local execution and data privacy, the Claude family demonstrated even more impressive performance in entity recognition tasks. In particular, Claude 3 Haiku achieved an outstanding overall accuracy of 0.912 (or 212 out of 232 entities correctly identified). To put this performance into perspective, let's examine a specific case study involving a 175-page document. Claude 3 Haiku correctly identified 31 out of 33 entities (police officers) in a 175-page transcript document. The total cost for this operation using Haiku was just $0.1275, significantly lower than its counterparts in the Claude 3 family. For comparison, the same task would have cost $1.53 with Claude 3.5 Sonnet and $7.65 with Claude 3 Opus.\n",
    "\n",
    "To put this in perspective, a human performing the same task would take approximately 5 hours, assuming an average reading speed of 225 words per minute and additional time for entity identification. At a rate of $30 per hour, the human labor cost would be around $150. This stark contrast—5 hours and $150 for a human versus near-instantaneous processing and $0.1275 for Claude 3 Haiku—underscores the remarkable efficiency and cost-effectiveness of AI in such tasks. The AI not only completes the job in seconds at a fraction of the cost but also maintains high accuracy. This analysis highlights Haiku's position as not just the most cost-effective option in the Claude 3 family, but also as a powerful tool for dramatically increasing productivity and reducing costs in tasks involving large-scale document analysis and entity recognition. (Need to be clear that labor costs in terms of dollars are only relevant for the comparative analysis that we're making when discussing the advantages of Haiku/Mixtral. Ultimately, whats most relevant are the improvements in how an individual's time can be allocated. Away with the menial work.)\n",
    "\n",
    "# Analysis\n",
    "\n",
    "In our evaluation of the all pages approach, we focused on comparing the performance of Claude models (Haiku and Sonnet) with Mixtral models (7B and 22B) in extracting different types of entities. This analysis provides insights into how these models handle single-word and multi-word entities, which is crucial for understanding their effectiveness in real-world document processing tasks.\n",
    "\n",
    "# Entity Complexity Observations\n",
    "\n",
    "1. **Claude Models Performance**:\n",
    "   - Claude 3.5 Sonnet showed the best overall performance, with the lowest percentage of unmatched single-word entities (18.18%) and a very low percentage of unmatched multi-word entities (5.08%).\n",
    "   - Claude 3 Haiku performed similarly well, with slightly higher unmatched percentages (21.82% for single-word and 4.52% for multi-word entities).\n",
    "\n",
    "2. **Mixtral Models Performance**:\n",
    "   - Both Mixtral models showed higher percentages of unmatched entities compared to the Claude models.\n",
    "   - Mixtral 7B performed better than Mixtral 22B, particularly in multi-word entity extraction.\n",
    "   - Mixtral 22B had the highest percentage of unmatched entities for both single-word (36.36%) and multi-word (22.60%) categories.\n",
    "\n",
    "3. **Single-Word vs. Multi-Word Entity Extraction**:\n",
    "   - All models generally performed better in extracting multi-word entities compared to single-word entities, as evidenced by the lower percentage of unmatched multi-word entities across all models.\n",
    "   - This trend was particularly pronounced in the Claude models, which showed a significant performance gap between single-word and multi-word entity extraction.\n",
    "\n",
    "4. **Model Size and Performance**:\n",
    "   - Interestingly, the larger Mixtral 22B model underperformed compared to its smaller 7B counterpart. This suggests that larger model size doesn't always correlate with better performance in specific tasks like entity extraction.\n",
    "   - In contrast, the more advanced Claude 3.5 Sonnet outperformed Claude 3 Haiku, albeit by a small margin.\n",
    "\n",
    "\n",
    "# Feature Importance Observations\n",
    "\n",
    "1. Haiku Model Analysis Summary\n",
    "For report documents, the Haiku model has a high R² score of 0.8812, indicating reliable predictions. The most important features are average entity length (0.4420) and percent single-word entities (0.3603), both above the absolute threshold of 0.333 and significantly contributing to the model's performance. Percent multi-word entities (0.1976) is below the threshold and therefore considered less important. For transcript documents, the low R² score (0.3643) suggests that the feature importances may be less reliable, so further model improvement is necessary before drawing conclusions about feature significance.\n",
    "\n",
    "2. Sonnet Model Analysis Summary\n",
    "For report documents, the Sonnet model has a high R² score of 0.8774, indicating reliable predictions. The most important feature is average entity length (0.4652), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Percent single-word entities (0.3112) and percent multi-word entities (0.2236) are below the threshold and therefore considered less important. For transcript documents, the high R² score (0.7261) indicates good model performance. Here, the feature importances are balanced but slightly below the threshold, with average entity length (0.3459), percent multi-word entities (0.3298), and percent single-word entities (0.3242) all playing notable roles.\n",
    "\n",
    "3. Mixtral 8b Model Analysis Summary\n",
    "For report documents, the Mixtral 8b model has a high R² score of 0.8349, indicating reliable predictions. The most important feature is percent multi-word entities (0.4079), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Average entity length (0.2924) and percent single-word entities (0.2997) are below the threshold and therefore considered less important. For transcript documents, the moderate R² score (0.6506) suggests good model performance. Here, the feature importances are balanced but slightly below the threshold, with average entity length (0.3250), percent multi-word entities (0.3425), and percent single-word entities (0.3325) all playing notable roles.\n",
    "\n",
    "4. Mixtral 22b Model Analysis Summary\n",
    "For report documents, the Mixtral 22b model has a high R² score of 0.8149, indicating reliable predictions. The most important feature is average entity length (0.4291), which is above the absolute threshold of 0.333 and significantly contributes to the model's performance. Percent single-word entities (0.3287) and percent multi-word entities (0.2423) are below the threshold and therefore considered less important. For transcript documents, the low R² score (0.3935) suggests that the feature importances may be less reliable, so further model improvement is necessary before drawing conclusions about feature significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allContext (iterate over all of the content within the document with one api call)\n",
    "\n",
    "data_sonnet_fullcontext = pd.read_csv('../data/allContext/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet_fullcontext['analysis_type'] = 'fullcontext_sonnet'\n",
    "\n",
    "data_haiku_fullcontext = pd.read_csv('../data/allContext/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku_fullcontext['analysis_type'] = 'fullcontext_haiku'\n",
    "\n",
    "data_opus_fullcontext = pd.read_csv('../data/allContext/results_claude-3-opus-20240229.csv')\n",
    "data_opus_fullcontext['analysis_type'] = 'fullcontext_opus'\n",
    "\n",
    "# AllPages (iterate over each page with one api call per page)\n",
    "\n",
    "data_haiku = pd.read_csv('../data/allPages/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku['analysis_type'] = 'allpages_haiku'\n",
    "\n",
    "data_sonnet = pd.read_csv('../data/allPages/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet['analysis_type'] = 'allpages_sonnet'\n",
    "\n",
    "data_mixtral_7b = pd.read_csv('../data/allPages/Mixtral-8x7B-Instruct-v0.1.csv')\n",
    "data_mixtral_7b['analysis_type'] = 'allpages_mixtral_7b'\n",
    "\n",
    "data_mixtral_22b = pd.read_csv('../data/allPages/Mixtral-8x22B-Instruct-v0.1.csv')\n",
    "data_mixtral_22b['analysis_type'] = 'allpages_mixtral_22b'\n",
    "\n",
    "# use Named Entity Recognition (NER) to calculate the number of entities on each page as a preprocessing step. \n",
    "# It then processes the document in three separate iterations. \n",
    "# In each iteration, it focuses on different top fractions of pages containing the most entities: \n",
    "# first the top 1/4th, then the top 1/2, and finally the top 3/4ths of the document. \n",
    "# For each fraction, the script identifies the pages with the highest number of entities and then iterates over each of those pages, \n",
    "# similar to the allPages script, to extract the entities.\n",
    "\n",
    "data_haiku_25 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-25per.csv')\n",
    "data_haiku_25['analysis_type'] = 'ner_25_haiku'\n",
    "\n",
    "data_haiku_50 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-50per.csv')\n",
    "data_haiku_50['analysis_type'] = 'ner_50_haiku'\n",
    "\n",
    "data_haiku_75 = pd.read_csv('../data/ner/results_claude-3-haiku-20240307-75per.csv')\n",
    "data_haiku_75['analysis_type'] = 'ner_75_haiku'\n",
    "\n",
    "data_sonnet_25 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-25per.csv')\n",
    "data_sonnet_25['analysis_type'] = 'ner_25_sonnet'\n",
    "\n",
    "data_sonnet_50 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-50per.csv')\n",
    "data_sonnet_50['analysis_type'] = 'ner_50_sonnet'\n",
    "\n",
    "data_sonnet_75 = pd.read_csv('../data/ner/results_claude-3-5-sonnet-20240620-75per.csv')\n",
    "data_sonnet_75['analysis_type'] = 'ner_75_sonnet'\n",
    "\n",
    "data_mixtral_7b_25 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_7b_25['analysis_type'] = 'ner_25_mixtral_7b'\n",
    "\n",
    "data_mixtral_7b_50 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_7b_50['analysis_type'] = 'ner_50_mixtral_7b'\n",
    "\n",
    "data_mixtral_7b_75 = pd.read_csv('../data/ner/Mixtral-8x7B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_7b_75['analysis_type'] = 'ner_75_mixtral_7b'\n",
    "\n",
    "data_mixtral_22b_25 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_22b_25['analysis_type'] = 'ner_25_mixtral_22b'\n",
    "\n",
    "data_mixtral_22b_50 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_22b_50['analysis_type'] = 'ner_50_mixtral_22b'\n",
    "\n",
    "data_mixtral_22b_75 = pd.read_csv('../data/ner/Mixtral-8x22B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_22b_75['analysis_type'] = 'ner_75_mixtral_22b'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "analysis_type\n",
       "allpages_sonnet         0.938840\n",
       "ner_75_sonnet           0.931097\n",
       "allpages_haiku          0.912932\n",
       "ner_50_sonnet           0.896382\n",
       "ner_75_haiku            0.875217\n",
       "ner_50_haiku            0.847949\n",
       "allpages_mixtral_7b     0.786638\n",
       "ner_25_sonnet           0.786434\n",
       "ner_75_mixtral_7b       0.748019\n",
       "ner_25_haiku            0.738128\n",
       "ner_50_mixtral_7b       0.729663\n",
       "allpages_mixtral_22b    0.729260\n",
       "ner_75_mixtral_22b      0.716072\n",
       "ner_50_mixtral_22b      0.701467\n",
       "fullcontext_opus        0.671461\n",
       "ner_25_mixtral_22b      0.616207\n",
       "fullcontext_haiku       0.607521\n",
       "ner_25_mixtral_7b       0.593477\n",
       "fullcontext_sonnet      0.520698\n",
       "Name: f_beta_score, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all DataFrames\n",
    "all_data = pd.concat([\n",
    "    data_sonnet_fullcontext, data_haiku_fullcontext, data_opus_fullcontext,\n",
    "    data_haiku, data_sonnet, data_mixtral_7b, data_mixtral_22b,\n",
    "    data_haiku_25, data_haiku_50, data_haiku_75,\n",
    "    data_sonnet_25, data_sonnet_50, data_sonnet_75,\n",
    "    data_mixtral_7b_25, data_mixtral_7b_50, data_mixtral_7b_75,\n",
    "    data_mixtral_22b_25, data_mixtral_22b_50, data_mixtral_22b_75\n",
    "])\n",
    "\n",
    "# Remove the specified columns\n",
    "columns_to_remove = ['Unnamed: 0.10', 'Unnamed: 0.9', 'Unnamed: 0.8', 'Unnamed: 0.7',\n",
    "                     'Unnamed: 0.6', 'Unnamed: 0.5', 'Unnamed: 0.4', 'Unnamed: 0.3',\n",
    "                     'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0']\n",
    "\n",
    "all_data = all_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# all_data.to_csv(\"../data/output/all_data.csv\")\n",
    "\n",
    "all_data.groupby(\"analysis_type\").f_beta_score.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis Type</th>\n",
       "      <th>total_single_word_entities</th>\n",
       "      <th>total_multi_word_entities</th>\n",
       "      <th>unmatched_single_word_entities</th>\n",
       "      <th>unmatched_multi_word_entities</th>\n",
       "      <th>pct_unmatched_single_word</th>\n",
       "      <th>pct_unmatched_multi_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21.818182</td>\n",
       "      <td>4.519774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>22.598870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>29.090909</td>\n",
       "      <td>15.819209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>55</td>\n",
       "      <td>177</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>5.084746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Analysis Type  total_single_word_entities  \\\n",
       "0        allpages_haiku                          55   \n",
       "1  allpages_mixtral_22b                          55   \n",
       "2   allpages_mixtral_7b                          55   \n",
       "3       allpages_sonnet                          55   \n",
       "\n",
       "   total_multi_word_entities  unmatched_single_word_entities  \\\n",
       "0                        177                              12   \n",
       "1                        177                              20   \n",
       "2                        177                              16   \n",
       "3                        177                              10   \n",
       "\n",
       "   unmatched_multi_word_entities  pct_unmatched_single_word  \\\n",
       "0                              8                  21.818182   \n",
       "1                             40                  36.363636   \n",
       "2                             28                  29.090909   \n",
       "3                              9                  18.181818   \n",
       "\n",
       "   pct_unmatched_multi_word  \n",
       "0                  4.519774  \n",
       "1                 22.598870  \n",
       "2                 15.819209  \n",
       "3                  5.084746  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_entity_characteristics(df):\n",
    "    results = []\n",
    "    \n",
    "    for analysis_type, group in df.groupby('analysis_type'):\n",
    "        all_entities = []\n",
    "        matched_entities = []\n",
    "        unmatched_entities = []\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            matched = set(literal_eval(row['matched_names']))\n",
    "            unmatched = set(literal_eval(row['unmatched_names']))\n",
    "            all_entities.extend(matched.union(unmatched))\n",
    "            matched_entities.extend(matched)\n",
    "            unmatched_entities.extend(unmatched)\n",
    "        \n",
    "        def categorize_entities(entities):\n",
    "            single_word = [e for e in entities if len(e.split()) == 1]\n",
    "            multi_word = [e for e in entities if len(e.split()) > 1]\n",
    "            return single_word, multi_word\n",
    "        \n",
    "        all_single, all_multi = categorize_entities(all_entities)\n",
    "        matched_single, matched_multi = categorize_entities(matched_entities)\n",
    "        \n",
    "        total_single = len(all_single)\n",
    "        total_multi = len(all_multi)\n",
    "        \n",
    "        unmatched_single = total_single - len(matched_single)\n",
    "        unmatched_multi = total_multi - len(matched_multi)\n",
    "        \n",
    "        pct_unmatched_single = (unmatched_single / total_single) * 100 if total_single > 0 else 0\n",
    "        pct_unmatched_multi = (unmatched_multi / total_multi) * 100 if total_multi > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'Analysis Type': analysis_type,\n",
    "            'total_single_word_entities': total_single,\n",
    "            'total_multi_word_entities': total_multi,\n",
    "            'unmatched_single_word_entities': unmatched_single,\n",
    "            'unmatched_multi_word_entities': unmatched_multi,\n",
    "            'pct_unmatched_single_word': pct_unmatched_single,\n",
    "            'pct_unmatched_multi_word': pct_unmatched_multi\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Assuming all_data is your input DataFrame\n",
    "compare_df = analyze_entity_characteristics(all_data)\n",
    "compare_df.to_csv(\"../data/output/compare.csv\")\n",
    "\n",
    "compare_df = compare_df[compare_df[\"Analysis Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis_Type</th>\n",
       "      <th>Document_Type</th>\n",
       "      <th>NER_Percentage</th>\n",
       "      <th>Average_F_Beta_Score</th>\n",
       "      <th>Average_RMSE</th>\n",
       "      <th>Average_R2</th>\n",
       "      <th>Average_Entities_Per_Token</th>\n",
       "      <th>Average_Entity_Length</th>\n",
       "      <th>Percent_Multi_Word_Entities</th>\n",
       "      <th>avg_entity_length</th>\n",
       "      <th>pct_multi_word_entities</th>\n",
       "      <th>pct_single_word_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.883899</td>\n",
       "      <td>0.068011</td>\n",
       "      <td>0.881211</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.442036</td>\n",
       "      <td>0.197638</td>\n",
       "      <td>0.360326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.945190</td>\n",
       "      <td>0.086383</td>\n",
       "      <td>0.364302</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.384843</td>\n",
       "      <td>0.304512</td>\n",
       "      <td>0.310646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.807369</td>\n",
       "      <td>0.055822</td>\n",
       "      <td>0.814945</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.429081</td>\n",
       "      <td>0.242252</td>\n",
       "      <td>0.328667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.642472</td>\n",
       "      <td>0.158415</td>\n",
       "      <td>0.393481</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.368268</td>\n",
       "      <td>0.292472</td>\n",
       "      <td>0.339260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.081680</td>\n",
       "      <td>0.834918</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.292390</td>\n",
       "      <td>0.407889</td>\n",
       "      <td>0.299721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.763246</td>\n",
       "      <td>0.117690</td>\n",
       "      <td>0.650579</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.324959</td>\n",
       "      <td>0.342524</td>\n",
       "      <td>0.332517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.895965</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.877446</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.465178</td>\n",
       "      <td>0.223642</td>\n",
       "      <td>0.311180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.986479</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.726137</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>1.702510</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.345939</td>\n",
       "      <td>0.329815</td>\n",
       "      <td>0.324246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Analysis_Type Document_Type NER_Percentage  Average_F_Beta_Score  \\\n",
       "0        allpages_haiku        report            N/A              0.883899   \n",
       "1        allpages_haiku    transcript            N/A              0.945190   \n",
       "2  allpages_mixtral_22b        report            N/A              0.807369   \n",
       "3  allpages_mixtral_22b    transcript            N/A              0.642472   \n",
       "4   allpages_mixtral_7b        report            N/A              0.807692   \n",
       "5   allpages_mixtral_7b    transcript            N/A              0.763246   \n",
       "6       allpages_sonnet        report            N/A              0.895965   \n",
       "7       allpages_sonnet    transcript            N/A              0.986479   \n",
       "\n",
       "   Average_RMSE  Average_R2  Average_Entities_Per_Token  \\\n",
       "0      0.068011    0.881211                    0.001355   \n",
       "1      0.086383    0.364302                    0.000444   \n",
       "2      0.055822    0.814945                    0.001355   \n",
       "3      0.158415    0.393481                    0.000444   \n",
       "4      0.081680    0.834918                    0.001355   \n",
       "5      0.117690    0.650579                    0.000444   \n",
       "6      0.050680    0.877446                    0.001355   \n",
       "7      0.013634    0.726137                    0.000444   \n",
       "\n",
       "   Average_Entity_Length  Percent_Multi_Word_Entities  avg_entity_length  \\\n",
       "0               1.797343                     0.779161           0.442036   \n",
       "1               1.702510                     0.695776           0.384843   \n",
       "2               1.797343                     0.779161           0.429081   \n",
       "3               1.702510                     0.695776           0.368268   \n",
       "4               1.797343                     0.779161           0.292390   \n",
       "5               1.702510                     0.695776           0.324959   \n",
       "6               1.797343                     0.779161           0.465178   \n",
       "7               1.702510                     0.695776           0.345939   \n",
       "\n",
       "   pct_multi_word_entities  pct_single_word_entities  \n",
       "0                 0.197638                  0.360326  \n",
       "1                 0.304512                  0.310646  \n",
       "2                 0.242252                  0.328667  \n",
       "3                 0.292472                  0.339260  \n",
       "4                 0.407889                  0.299721  \n",
       "5                 0.342524                  0.332517  \n",
       "6                 0.223642                  0.311180  \n",
       "7                 0.329815                  0.324246  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_entity_complexity_features(row):\n",
    "    matched = set(literal_eval(row['matched_names']))\n",
    "    unmatched = set(literal_eval(row['unmatched_names']))\n",
    "    all_entities = matched.union(unmatched)\n",
    "    \n",
    "    if all_entities:\n",
    "        avg_entity_length = np.mean([len(entity.split()) for entity in all_entities])\n",
    "        pct_multi_word = sum(len(entity.split()) > 1 for entity in all_entities) / len(all_entities)\n",
    "        pct_single_word = sum(len(entity.split()) == 1 for entity in all_entities) / len(all_entities)\n",
    "    else:\n",
    "        avg_entity_length = 0\n",
    "        pct_multi_word = 0\n",
    "        pct_single_word = 0\n",
    "    \n",
    "    return pd.Series({\n",
    "        'avg_entity_length': avg_entity_length,\n",
    "        'pct_multi_word_entities': pct_multi_word,\n",
    "        'pct_single_word_entities': pct_single_word\n",
    "    })\n",
    "\n",
    "def analyze_data(data):\n",
    "    complexity_features = data.apply(calculate_entity_complexity_features, axis=1)\n",
    "    data = pd.concat([data, complexity_features], axis=1)\n",
    "    \n",
    "    data['entities_per_token'] = data['total_ground_truth'] / data['token_count']\n",
    "    \n",
    "    X = data[['avg_entity_length', 'pct_multi_word_entities', 'pct_single_word_entities']]\n",
    "    y = data['f_beta_score']\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    predictions = rf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    r2 = r2_score(y, predictions)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    feature_names = X.columns\n",
    "\n",
    "    feature_importances = {name: importance for name, importance in zip(feature_names, importances)}\n",
    "\n",
    "    return rmse, r2, feature_importances, data\n",
    "\n",
    "def process_data(all_data):\n",
    "    results = []\n",
    "    for analysis_type, group in all_data.groupby('analysis_type'):\n",
    "        if 'filetype' in group.columns:\n",
    "            doc_types = group['filetype'].unique()\n",
    "        else:\n",
    "            doc_types = ['combined']\n",
    "        \n",
    "        for doc_type in doc_types:\n",
    "            if doc_type != 'combined':\n",
    "                filtered_data = group[group['filetype'] == doc_type]\n",
    "            else:\n",
    "                filtered_data = group\n",
    "            \n",
    "            if not filtered_data.empty:\n",
    "                rmse, r2, feature_importances, updated_data = analyze_data(filtered_data)\n",
    "                result = {\n",
    "                    'Analysis_Type': analysis_type,\n",
    "                    'Document_Type': doc_type,\n",
    "                    'Average_F_Beta_Score': updated_data['f_beta_score'].mean(),\n",
    "                    'Average_RMSE': rmse,\n",
    "                    'Average_R2': r2,\n",
    "                    'Average_Entities_Per_Token': updated_data['entities_per_token'].mean(),\n",
    "                    'Average_Entity_Length': updated_data['avg_entity_length'].mean(),\n",
    "                    'Percent_Multi_Word_Entities': updated_data['pct_multi_word_entities'].mean(),\n",
    "                    **feature_importances\n",
    "                }\n",
    "                \n",
    "                # Extract NER percentage if it's an NER analysis type\n",
    "                if 'ner' in analysis_type:\n",
    "                    result['NER_Percentage'] = analysis_type.split('_')[1]\n",
    "                else:\n",
    "                    result['NER_Percentage'] = 'N/A'\n",
    "                \n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "results = process_data(all_data)\n",
    "results_df = pd.DataFrame(results)\n",
    "groupby_columns = ['Analysis_Type', 'Document_Type', 'NER_Percentage']\n",
    "grouped_results_df = results_df.groupby(groupby_columns).mean().reset_index()\n",
    "# grouped_results_df.to_csv(\"../data/output/grouped.csv\")\n",
    "grouped_results_df = grouped_results_df[grouped_results_df[\"Analysis_Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "grouped_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Feature Importances (Excluding Low R² Scores)\n",
      "Average Entity Length: 0.3833\n",
      "Percent Multi-Word Entities: 0.2906\n",
      "Percent Single-Word Entities: 0.3261\n",
      "\n",
      "Absolute Threshold for Importance: 0.3333\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_feature_importances(grouped_results_df, r2_threshold=0.5):\n",
    "    valid_feature_importances = {\n",
    "        'Average Entity Length': [],\n",
    "        'Percent Multi-Word Entities': [],\n",
    "        'Percent Single-Word Entities': []\n",
    "    }\n",
    "\n",
    "    for index, row in grouped_results_df.iterrows():\n",
    "        if row['Average_R2'] >= r2_threshold:\n",
    "            valid_feature_importances['Average Entity Length'].append(row['avg_entity_length'])\n",
    "            valid_feature_importances['Percent Multi-Word Entities'].append(row['pct_multi_word_entities'])\n",
    "            valid_feature_importances['Percent Single-Word Entities'].append(row['pct_single_word_entities'])\n",
    "\n",
    "    valid_mean_feature_importances = {feature: sum(values) / len(values) for feature, values in valid_feature_importances.items()}\n",
    "\n",
    "    return valid_mean_feature_importances\n",
    "\n",
    "mean_feature_importances = calculate_mean_feature_importances(grouped_results_df)\n",
    "\n",
    "print(\"Mean Feature Importances (Excluding Low R² Scores)\")\n",
    "for feature, importance in mean_feature_importances.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "absolute_threshold = sum(mean_feature_importances.values()) / len(mean_feature_importances)\n",
    "print(f\"\\nAbsolute Threshold for Importance: {absolute_threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future research \n",
    "1. Building on the work of exploring entity string characteristics, lets extract the officers title, not role, based on the prefix. What effect does the title being in the text have on the models ability to identify the officer? We're looking for reasoning metrics. \n",
    "\n",
    "---\n",
    "\n",
    "[1] Guha, N., et al. (2024). The Future of Computational Law. Cross-disciplinary Research in Computational Law (CRCL), 2(2). https://journalcrcl.org/crcl/article/view/62/28\n",
    "\n",
    "[2] https://blog.langchain.dev/multi-needle-in-a-haystack/\n",
    "\n",
    "other source: https://arxiv.org/pdf/2405.20362"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
