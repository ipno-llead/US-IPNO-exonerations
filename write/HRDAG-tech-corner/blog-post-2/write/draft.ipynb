{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "Image(filename='../data/banner.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Introduction](#intro)\n",
    "2. [Analysis Types](#types)\n",
    "3. [Results](#results)\n",
    "4. [Addressing Precision and F1 Scores](#scores)\n",
    "5. [Key Insight](#insights)\n",
    "6. [Additional Insights](#xtra)\n",
    "7. [Feature Importance Analysis](#importance)\n",
    "8. [Conclusions](#conclusions)\n",
    "9. [Resources](#links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/allContext/results_claude-3-5-sonnet-20240620.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, path \u001b[38;5;129;01min\u001b[39;00m files\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 49\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mread_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsvf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label\n\u001b[1;32m     51\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m, in \u001b[0;36mread_format\u001b[0;34m(csvf)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_format\u001b[39m(csvf):\n\u001b[0;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsvf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproportion_matched\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mpercentage_matched\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mround\u001b[39m(x\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      5\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf_beta_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/allContext/results_claude-3-5-sonnet-20240620.csv'"
     ]
    }
   ],
   "source": [
    "# import tables\n",
    "def read_format(csvf):\n",
    "    df = pd.read_csv(csvf)\n",
    "    df['proportion_matched'] = df.percentage_matched.apply(lambda x: round(x/100, 2))\n",
    "    metrics = ['precision', 'recall', 'f1_score', 'f_beta_score']\n",
    "    for metric in metrics:\n",
    "        df[metric] = df[metric].apply(lambda x: round(x, 2))\n",
    "    return df\n",
    "\n",
    "# PROPOSED BUILD (removes whitespace and some repetition)\n",
    "# NOTE: `read_format()` was not used originally but I've added it\n",
    "files = {\n",
    "    # allContext (iterate over all of the content within the document with one api call)\n",
    "    'fullcontext_sonnet': '../data/allContext/results_claude-3-5-sonnet-20240620.csv',\n",
    "    'fullcontext_haiku': '../data/allContext/results_claude-3-haiku-20240307.csv',\n",
    "    'fullcontext_opus': '../data/allContext/results_claude-3-opus-20240229.csv',\n",
    "    'fullcontext_nemo': '../data/allContext/results_open-mistral-nemo.csv',\n",
    "\n",
    "    # AllPages (iterate over each page with one api call per page)\n",
    "    'allpages_haiku': '../data/allPages/results_claude-3-haiku-20240307.csv',\n",
    "    'allpages_sonnet': '../data/allPages/results_claude-3-5-sonnet-20240620.csv',\n",
    "    'allpages_mixtral_7b': '../data/allPages/Mixtral-8x7B-Instruct-v0.1.csv',\n",
    "    'allpages_mixtral_22b': '../data/allPages/Mixtral-8x22B-Instruct-v0.1.csv',\n",
    "\n",
    "    # use Named Entity Recognition (NER) to calculate the number of entities on each page as a preprocessing step.\n",
    "    # It then processes the document in three separate iterations.\n",
    "    # In each iteration, it focuses on different top fractions of pages containing the most entities:\n",
    "    # first the top 1/4th, then the top 1/2, and finally the top 3/4ths of the document.\n",
    "    # For each fraction, the script identifies the pages with the highest number of entities and then iterates over each of those pages,\n",
    "    # similar to the allPages script, to extract the entities.\n",
    "    'ner_25_haiku': '../data/ner/results_claude-3-haiku-20240307-25per.csv',\n",
    "    'ner_50_haiku': '../data/ner/results_claude-3-haiku-20240307-50per.csv',\n",
    "    'ner_75_haiku': '../data/ner/results_claude-3-haiku-20240307-75per.csv',\n",
    "    'ner_25_sonnet': '../data/ner/results_claude-3-5-sonnet-20240620-25per.csv',\n",
    "    'ner_50_sonnet': '../data/ner/results_claude-3-5-sonnet-20240620-50per.csv',\n",
    "    'ner_75_sonnet': '../data/ner/results_claude-3-5-sonnet-20240620-75per.csv',\n",
    "    'ner_25_mixtral_7b': '../data/ner/Mixtral-8x7B-Instruct-v0.1-25per.csv',\n",
    "    'ner_50_mixtral_7b': '../data/ner/Mixtral-8x7B-Instruct-v0.1-50per.csv',\n",
    "    'ner_75_mixtral_7b': '../data/ner/Mixtral-8x7B-Instruct-v0.1-75per.csv',\n",
    "    'ner_25_mixtral_22b': '../data/ner/Mixtral-8x22B-Instruct-v0.1-25per.csv',\n",
    "    'ner_50_mixtral_22b': '../data/ner/Mixtral-8x22B-Instruct-v0.1-50per.csv',\n",
    "    'ner_75_mixtral_22b': '../data/ner/Mixtral-8x22B-Instruct-v0.1-75per.csv',\n",
    "    # Experimental vision model results\n",
    "    'haiku_vision_allpages': '../data/Vision/results_claude-3-haiku-20240307.csv',\n",
    "    'sonnet_vision_allpages': '../data/Vision/results_claude-3-5-sonnet-20240620.csv',\n",
    "}\n",
    "dfs = []\n",
    "for label, path in files.items():\n",
    "    df = read_format(csvf=path)\n",
    "    df['analysis_type'] = label\n",
    "    dfs.append(df)\n",
    "testdf = pd.concat(dfs)\n",
    "testdf = testdf.drop(columns=[\n",
    "    col for col in testdf.columns\n",
    "    if ('unnamed' in col.lower()) | (('file' in col.lower()) & ('name' in col.lower()))\n",
    "    ], errors='ignore')\n",
    "testdf = testdf.rename(columns={\"total_ground_truth\": \"n_entities\"})\n",
    "\n",
    "# EXISTING BUILD\n",
    "\n",
    "# allContext (iterate over all of the content within the document with one api call)\n",
    "data_sonnet_fullcontext = read_format(csvf='../data/allContext/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet_fullcontext['analysis_type'] = 'fullcontext_sonnet'\n",
    "data_haiku_fullcontext = read_format(csvf='../data/allContext/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku_fullcontext['analysis_type'] = 'fullcontext_haiku'\n",
    "data_opus_fullcontext = read_format(csvf='../data/allContext/results_claude-3-opus-20240229.csv')\n",
    "data_opus_fullcontext['analysis_type'] = 'fullcontext_opus'\n",
    "data_nemo_fullcontext = read_format(csvf=\"../data/allContext/results_open-mistral-nemo.csv\")\n",
    "data_nemo_fullcontext['analysis_type'] = 'fullcontext_nemo'\n",
    "\n",
    "# AllPages (iterate over each page with one api call per page)\n",
    "data_haiku = read_format(csvf='../data/allPages/results_claude-3-haiku-20240307.csv')\n",
    "data_haiku['analysis_type'] = 'allpages_haiku'\n",
    "data_sonnet = read_format(csvf='../data/allPages/results_claude-3-5-sonnet-20240620.csv')\n",
    "data_sonnet['analysis_type'] = 'allpages_sonnet'\n",
    "data_mixtral_7b = read_format(csvf='../data/allPages/Mixtral-8x7B-Instruct-v0.1.csv')\n",
    "data_mixtral_7b['analysis_type'] = 'allpages_mixtral_7b'\n",
    "data_mixtral_22b = read_format(csvf='../data/allPages/Mixtral-8x22B-Instruct-v0.1.csv')\n",
    "data_mixtral_22b['analysis_type'] = 'allpages_mixtral_22b'\n",
    "\n",
    "# use Named Entity Recognition (NER) to calculate the number of entities on each page as a preprocessing step.\n",
    "# It then processes the document in three separate iterations.\n",
    "# In each iteration, it focuses on different top fractions of pages containing the most entities:\n",
    "# first the top 1/4th, then the top 1/2, and finally the top 3/4ths of the document.\n",
    "# For each fraction, the script identifies the pages with the highest number of entities and then iterates over each of those pages,\n",
    "# similar to the allPages script, to extract the entities.\n",
    "data_haiku_25 = read_format(csvf='../data/ner/results_claude-3-haiku-20240307-25per.csv')\n",
    "data_haiku_25['analysis_type'] = 'ner_25_haiku'\n",
    "data_haiku_50 = read_format(csvf='../data/ner/results_claude-3-haiku-20240307-50per.csv')\n",
    "data_haiku_50['analysis_type'] = 'ner_50_haiku'\n",
    "data_haiku_75 = read_format(csvf='../data/ner/results_claude-3-haiku-20240307-75per.csv')\n",
    "data_haiku_75['analysis_type'] = 'ner_75_haiku'\n",
    "\n",
    "data_sonnet_25 = read_format(csvf='../data/ner/results_claude-3-5-sonnet-20240620-25per.csv')\n",
    "data_sonnet_25['analysis_type'] = 'ner_25_sonnet'\n",
    "data_sonnet_50 = read_format(csvf='../data/ner/results_claude-3-5-sonnet-20240620-50per.csv')\n",
    "data_sonnet_50['analysis_type'] = 'ner_50_sonnet'\n",
    "data_sonnet_75 = read_format(csvf='../data/ner/results_claude-3-5-sonnet-20240620-75per.csv')\n",
    "data_sonnet_75['analysis_type'] = 'ner_75_sonnet'\n",
    "\n",
    "data_mixtral_7b_25 = read_format(csvf='../data/ner/Mixtral-8x7B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_7b_25['analysis_type'] = 'ner_25_mixtral_7b'\n",
    "data_mixtral_7b_50 = read_format(csvf='../data/ner/Mixtral-8x7B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_7b_50['analysis_type'] = 'ner_50_mixtral_7b'\n",
    "data_mixtral_7b_75 = read_format(csvf='../data/ner/Mixtral-8x7B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_7b_75['analysis_type'] = 'ner_75_mixtral_7b'\n",
    "\n",
    "data_mixtral_22b_25 = read_format(csvf='../data/ner/Mixtral-8x22B-Instruct-v0.1-25per.csv')\n",
    "data_mixtral_22b_25['analysis_type'] = 'ner_25_mixtral_22b'\n",
    "data_mixtral_22b_50 = read_format(csvf='../data/ner/Mixtral-8x22B-Instruct-v0.1-50per.csv')\n",
    "data_mixtral_22b_50['analysis_type'] = 'ner_50_mixtral_22b'\n",
    "data_mixtral_22b_75 = read_format(csvf='../data/ner/Mixtral-8x22B-Instruct-v0.1-75per.csv')\n",
    "data_mixtral_22b_75['analysis_type'] = 'ner_75_mixtral_22b'\n",
    "\n",
    "data_haiku_vision = read_format(csvf=\"../data/Vision/results_claude-3-haiku-20240307.csv\")\n",
    "data_haiku_vision['analysis_type'] = 'haiku_vision_allpages'\n",
    "data_sonnet_vision = read_format(csvf=\"../data/Vision/results_claude-3-5-sonnet-20240620.csv\")\n",
    "data_sonnet_vision['analysis_type'] = 'sonnet_vision_allpages'\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "df = pd.concat([\n",
    "    data_sonnet_fullcontext, data_haiku_fullcontext, data_opus_fullcontext, data_nemo_fullcontext,\n",
    "    data_haiku, data_sonnet, data_mixtral_7b, data_mixtral_22b,\n",
    "    data_haiku_25, data_haiku_50, data_haiku_75,\n",
    "    data_sonnet_25, data_sonnet_50, data_sonnet_75,\n",
    "    data_mixtral_7b_25, data_mixtral_7b_50, data_mixtral_7b_75,\n",
    "    data_mixtral_22b_25, data_mixtral_22b_50, data_mixtral_22b_75, data_haiku_vision, data_sonnet_vision\n",
    "])\n",
    "\n",
    "# Remove the specified columns\n",
    "columns_to_remove = ['Unnamed: 0.10', 'Unnamed: 0.9', 'Unnamed: 0.8', 'Unnamed: 0.7',\n",
    "                     'Unnamed: 0.6', 'Unnamed: 0.5', 'Unnamed: 0.4', 'Unnamed: 0.3',\n",
    "                     'Unnamed: 0.2', 'Unnamed: 0.1', 'Unnamed: 0', \"file_name\", \"filename\"]\n",
    "\n",
    "df = df.drop(columns=columns_to_remove, errors='ignore')\n",
    "df = df.rename(columns={\"total_ground_truth\": \"n_entities\"})\n",
    "df_names = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert testdf.equals(df), f\"Test df build is not matching existing df build\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "In the previous chapter of this series, we explored the application of large language models (LLMs) for structured information extraction from wrongful conviction case files using retrieval augmented generation (RAG). However, recent advancements in LLM technology have necessitated a re-evaluation of our information extraction pipeline. Models like Gemini 1.5 Pro with its one million token context window and Claude 3 Opus/Sonnet/Haiku with a 200k context window now allow entire documents to fit within a single context window, potentially eliminating the need for retrieving specific document pages. Furthermore, the emergence of cost-effective yet high-performing models like Claude Haiku make it feasible to iterate over every page in a document, rather than attempting to extract only the most relevant pieces for analysis.\n",
    "\n",
    "This follow-up chapter aims to reconsider the fundamentals of our information extraction pipeline and explore the impact of both larger proprietary models and emerging open-source alternatives on our research. Our approachevaluating LLMs in legal research by focusing on entity extractionaligns with recent computational law research suggesting that AI might be more effective in narrow, well-defined legal applications [1](https://journalcrcl.org/crcl/article/view/62/28). By concentrating on the specific task of identifying police officers in wrongful conviction case files, we can assess LLM performance in a constrained legal context that is more amenable to large-scale evaluation due to its relative simplicity. This targeted approach differs from more complex tasks, such as writing legal briefs, attempted by generative AI legal research tools like Lexis+ AI and Casetext, which recent studies have shown to be susceptible to high rates of hallucination [2](https://arxiv.org/pdf/2405.20362). Unlike generative tasks where correctness can be subjective, identifying specific entities allows for clear, binary assessments of performance (correct identification vs. incorrect or missed identification), enabling more robust and quantifiable evaluation metrics. While our approach may still produce false positives, entity extraction tasks are generally less susceptible to the negative effects of hallucination, as these errors can often be identified and mitigated through careful prompt engineering. This focused approach allows us to develop techniques that can potentially extend to other entities (e.g., witnesses, victims, locations, evidence, legal precedents) and legal document types, while providing a more robust framework for assessing and improving AI performance in legal applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Types <a class=\"anchor\" id=\"types\"></a>\n",
    "\n",
    "This follow-up chapter aims to reconsider the fundamentals of our information extraction pipeline and explore the impact of both larger proprietary Claude models and Mixtral models, an emerging open-source alternative, on extracting the names of police officers from case files. Our analysis compares three entity extraction strategies across both proprietary Claude models and open-source Mixtral models, each offering unique advantages and potential trade-offs in processing legal documents:\n",
    "\n",
    "1. **All Pages**: This method iterates over each page in the document sequentially. This method was tested using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants).\n",
    "\n",
    "2. **Named Entity Recognition (NER) Based Filtering**: This method preprocesses the document to identify pages with the highest concentration of entities, then analyzes these high-density pages. This method was tested with varying percentages (25%, 50%, and 75%) of the most entity-rich pages using Claude 3 Haiku, Claude 3.5 Sonnet, and Mixtral models (7B and 22B variants).\n",
    "\n",
    "3. **Full Context**: This method processes the entire document at once, utilizing the full context window capabilities of Claude 3 Haiku, Claude 3.5 Sonnet, and Claude 3 Opus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_count</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>percentage_matched</th>\n",
       "      <th>matched_names</th>\n",
       "      <th>unmatched_names</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f_beta_score</th>\n",
       "      <th>token_count</th>\n",
       "      <th>filetype</th>\n",
       "      <th>model</th>\n",
       "      <th>unique_entity_count</th>\n",
       "      <th>analysis_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>{'g. noble', 'raymond loosemore', 'gerald ursi...</td>\n",
       "      <td>{\"harry o'neal\", 'jefferson', 'spong', 'thomas...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5871</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>11</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>{'barrett morton'}</td>\n",
       "      <td>{'garner', 'kenneth leary'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>41487</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>3</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>{'martin venezia', 'pat roche', 'james dupuis'...</td>\n",
       "      <td>{'davillier', 'gebbia', 'walley goodey', 'wood...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>102827</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>32</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>{'martin venezia', 'jerry ursin', 'sam gebbia'...</td>\n",
       "      <td>{'little'}</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>22254</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>6</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>23.076923</td>\n",
       "      <td>{'marco nuzzolillo', 'larry morin', 'ralph pep...</td>\n",
       "      <td>{'denour j', 'jerry hall', 'carson', 'masson',...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>26172</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>13</td>\n",
       "      <td>fullcontext_sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   matched_count  n_entities  percentage_matched  \\\n",
       "0              6          11           54.545455   \n",
       "1              1           3           33.333333   \n",
       "2              4          32           12.500000   \n",
       "3              5           6           83.333333   \n",
       "4              3          13           23.076923   \n",
       "\n",
       "                                       matched_names  \\\n",
       "0  {'g. noble', 'raymond loosemore', 'gerald ursi...   \n",
       "1                                 {'barrett morton'}   \n",
       "2  {'martin venezia', 'pat roche', 'james dupuis'...   \n",
       "3  {'martin venezia', 'jerry ursin', 'sam gebbia'...   \n",
       "4  {'marco nuzzolillo', 'larry morin', 'ralph pep...   \n",
       "\n",
       "                                     unmatched_names  true_positives  \\\n",
       "0  {\"harry o'neal\", 'jefferson', 'spong', 'thomas...               6   \n",
       "1                        {'garner', 'kenneth leary'}               1   \n",
       "2  {'davillier', 'gebbia', 'walley goodey', 'wood...               4   \n",
       "3                                         {'little'}               5   \n",
       "4  {'denour j', 'jerry hall', 'carson', 'masson',...               3   \n",
       "\n",
       "   false_positives  precision    recall  f1_score  f_beta_score  token_count  \\\n",
       "0                0   1.000000  0.545455  0.705882      0.600000         5871   \n",
       "1                0   1.000000  0.333333  0.500000      0.384615        41487   \n",
       "2                3   0.571429  0.125000  0.205128      0.148148       102827   \n",
       "3                0   1.000000  0.833333  0.909091      0.862069        22254   \n",
       "4                3   0.500000  0.230769  0.315789      0.258621        26172   \n",
       "\n",
       "     filetype                       model  unique_entity_count  \\\n",
       "0      report  claude-3-5-sonnet-20240620                   11   \n",
       "1  transcript  claude-3-5-sonnet-20240620                    3   \n",
       "2  transcript  claude-3-5-sonnet-20240620                   32   \n",
       "3  transcript  claude-3-5-sonnet-20240620                    6   \n",
       "4      report  claude-3-5-sonnet-20240620                   13   \n",
       "\n",
       "        analysis_type  \n",
       "0  fullcontext_sonnet  \n",
       "1  fullcontext_sonnet  \n",
       "2  fullcontext_sonnet  \n",
       "3  fullcontext_sonnet  \n",
       "4  fullcontext_sonnet  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results <a class=\"anchor\" id=\"results\"></a>\n",
    "\n",
    "Model performance was evaluated based on recall scores. Recall measures the proportion of police officers that were correctly identified by each model. To account for the stochastic nature of these models, we conducted a repeated analysis on a single representative configuration: Claude Haiku with the all pages approach. This choice was based on Claude Haiku's performance being in the middle between Mixtral models and Claude models in this analysis, as well as the comprehensive nature of the all pages approach. Over five runs, we observed a margin of error of 0.029. While this variability is specific to this configuration, due to costs associated with running each process five times, it's expected to be a reasonable representation of the overall margins of error across different models and approaches.\n",
    "\n",
    "Our findings across the different approaches and models are as follows:\n",
    "\n",
    "1. **All Pages Approach**:\n",
    "   - Claude 3.5 Sonnet performed best, with a score of 0.929922.\n",
    "   - Claude 3 Haiku followed closely with 0.912539.\n",
    "   - Mixtral models, while scoring lower, showed promising results:\n",
    "     - Mixtral 7B achieved 0.758921\n",
    "     - Mixtral 22B scored 0.693101\n",
    "\n",
    "2. **NER-Based Approach**:\n",
    "   - A clear trend emerged: performance generally improved as the percentage of analyzed pages increased:\n",
    "     - For Claude 3.5 Sonnet:\n",
    "       - 25% of pages: 0.759347\n",
    "       - 50% of pages: 0.877395\n",
    "       - 75% of pages: 0.918781\n",
    "     - Similarly for Claude 3 Haiku:\n",
    "       - 25% of pages: 0.708429\n",
    "       - 50% of pages: 0.825478\n",
    "       - 75% of pages: 0.857535\n",
    "   - Mixtral models followed the same pattern, though with lower overall scores:\n",
    "     - Mixtral 7B:\n",
    "       - 25% of pages: 0.553632\n",
    "       - 50% of pages: 0.691882\n",
    "       - 75% of pages: 0.713628\n",
    "     - Mixtral 22B:\n",
    "       - 25% of pages: 0.577523\n",
    "       - 50% of pages: 0.660438\n",
    "       - 75% of pages: 0.682686\n",
    "   \n",
    "3. **Full Context Approach**:\n",
    "   - This method yielded varied results across models:\n",
    "     - Claude 3 Haiku: 0.565780\n",
    "     - Claude 3 Opus: 0.632819\n",
    "     - Claude 3.5 Sonnet: 0.478743\n",
    "     - Mistral NeMo: 0.200015\n",
    "\n",
    "**Note on Vision Models:**\n",
    "For the purposes of testing, we also performed this analysis using vision-capable models. The scores for the all pages approach were:\n",
    "- Claude 3.5 Sonnet (Vision): 0.669457\n",
    "- Claude 3 Haiku (Vision): 0.653975\n",
    "\n",
    "These results suggest potential for vision models in document analysis tasks. Future research will focus more extensively on leveraging and optimizing vision models for entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f_beta_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>allpages_sonnet</th>\n",
       "      <td>0.488414</td>\n",
       "      <td>0.929922</td>\n",
       "      <td>0.612635</td>\n",
       "      <td>0.753952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_sonnet</th>\n",
       "      <td>0.510440</td>\n",
       "      <td>0.918781</td>\n",
       "      <td>0.627829</td>\n",
       "      <td>0.757707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_haiku</th>\n",
       "      <td>0.292836</td>\n",
       "      <td>0.912539</td>\n",
       "      <td>0.417799</td>\n",
       "      <td>0.590450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_sonnet</th>\n",
       "      <td>0.537045</td>\n",
       "      <td>0.877395</td>\n",
       "      <td>0.637830</td>\n",
       "      <td>0.746912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_haiku</th>\n",
       "      <td>0.320401</td>\n",
       "      <td>0.857535</td>\n",
       "      <td>0.434373</td>\n",
       "      <td>0.585655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_haiku</th>\n",
       "      <td>0.353012</td>\n",
       "      <td>0.825478</td>\n",
       "      <td>0.459295</td>\n",
       "      <td>0.597251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_sonnet</th>\n",
       "      <td>0.584956</td>\n",
       "      <td>0.759347</td>\n",
       "      <td>0.627289</td>\n",
       "      <td>0.688083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_mixtral_7b</th>\n",
       "      <td>0.179858</td>\n",
       "      <td>0.758921</td>\n",
       "      <td>0.275315</td>\n",
       "      <td>0.419651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_mixtral_7b</th>\n",
       "      <td>0.210100</td>\n",
       "      <td>0.713628</td>\n",
       "      <td>0.302178</td>\n",
       "      <td>0.435428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_haiku</th>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.708429</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>0.587024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allpages_mixtral_22b</th>\n",
       "      <td>0.256271</td>\n",
       "      <td>0.693101</td>\n",
       "      <td>0.344155</td>\n",
       "      <td>0.462418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_mixtral_7b</th>\n",
       "      <td>0.254421</td>\n",
       "      <td>0.691882</td>\n",
       "      <td>0.339417</td>\n",
       "      <td>0.457751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_75_mixtral_22b</th>\n",
       "      <td>0.314018</td>\n",
       "      <td>0.682686</td>\n",
       "      <td>0.401642</td>\n",
       "      <td>0.510642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonnet_vision_allpages</th>\n",
       "      <td>0.454749</td>\n",
       "      <td>0.669457</td>\n",
       "      <td>0.505718</td>\n",
       "      <td>0.575126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_50_mixtral_22b</th>\n",
       "      <td>0.350250</td>\n",
       "      <td>0.660438</td>\n",
       "      <td>0.426463</td>\n",
       "      <td>0.520435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haiku_vision_allpages</th>\n",
       "      <td>0.370203</td>\n",
       "      <td>0.653975</td>\n",
       "      <td>0.449842</td>\n",
       "      <td>0.539262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_opus</th>\n",
       "      <td>0.785303</td>\n",
       "      <td>0.632819</td>\n",
       "      <td>0.687041</td>\n",
       "      <td>0.651243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_mixtral_22b</th>\n",
       "      <td>0.455386</td>\n",
       "      <td>0.577523</td>\n",
       "      <td>0.466790</td>\n",
       "      <td>0.512166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_haiku</th>\n",
       "      <td>0.724370</td>\n",
       "      <td>0.565780</td>\n",
       "      <td>0.621626</td>\n",
       "      <td>0.584906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ner_25_mixtral_7b</th>\n",
       "      <td>0.310901</td>\n",
       "      <td>0.553632</td>\n",
       "      <td>0.367357</td>\n",
       "      <td>0.441235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_sonnet</th>\n",
       "      <td>0.824666</td>\n",
       "      <td>0.478743</td>\n",
       "      <td>0.577878</td>\n",
       "      <td>0.511514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullcontext_nemo</th>\n",
       "      <td>0.488304</td>\n",
       "      <td>0.200015</td>\n",
       "      <td>0.251476</td>\n",
       "      <td>0.216267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        precision    recall  f1_score  f_beta_score\n",
       "analysis_type                                                      \n",
       "allpages_sonnet          0.488414  0.929922  0.612635      0.753952\n",
       "ner_75_sonnet            0.510440  0.918781  0.627829      0.757707\n",
       "allpages_haiku           0.292836  0.912539  0.417799      0.590450\n",
       "ner_50_sonnet            0.537045  0.877395  0.637830      0.746912\n",
       "ner_75_haiku             0.320401  0.857535  0.434373      0.585655\n",
       "ner_50_haiku             0.353012  0.825478  0.459295      0.597251\n",
       "ner_25_sonnet            0.584956  0.759347  0.627289      0.688083\n",
       "allpages_mixtral_7b      0.179858  0.758921  0.275315      0.419651\n",
       "ner_75_mixtral_7b        0.210100  0.713628  0.302178      0.435428\n",
       "ner_25_haiku             0.451221  0.708429  0.503302      0.587024\n",
       "allpages_mixtral_22b     0.256271  0.693101  0.344155      0.462418\n",
       "ner_50_mixtral_7b        0.254421  0.691882  0.339417      0.457751\n",
       "ner_75_mixtral_22b       0.314018  0.682686  0.401642      0.510642\n",
       "sonnet_vision_allpages   0.454749  0.669457  0.505718      0.575126\n",
       "ner_50_mixtral_22b       0.350250  0.660438  0.426463      0.520435\n",
       "haiku_vision_allpages    0.370203  0.653975  0.449842      0.539262\n",
       "fullcontext_opus         0.785303  0.632819  0.687041      0.651243\n",
       "ner_25_mixtral_22b       0.455386  0.577523  0.466790      0.512166\n",
       "fullcontext_haiku        0.724370  0.565780  0.621626      0.584906\n",
       "ner_25_mixtral_7b        0.310901  0.553632  0.367357      0.441235\n",
       "fullcontext_sonnet       0.824666  0.478743  0.577878      0.511514\n",
       "fullcontext_nemo         0.488304  0.200015  0.251476      0.216267"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = df.groupby(\"analysis_type\").agg({\n",
    "    \"precision\": \"mean\",\n",
    "    \"recall\": \"mean\",\n",
    "    \"f1_score\": \"mean\",\n",
    "    \"f_beta_score\": \"mean\"\n",
    "}).sort_values(\"recall\", ascending=False)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Precision and F1 Scores <a class=\"anchor\" id=\"scores\"></a>\n",
    "\n",
    "While our analysis shows high recall scores across the different models with the all pages method, it's important to note that the F1 scores are relatively low due to poor precision (high false positive rates). However, this is not a significant concern in our context due to our prompting strategy. Our approach requires the model to provide a comprehensive profile of each identified individual, making it easy to filter out false positives. Here's an example of our prompting template:\n",
    "\n",
    "```python\n",
    "template = \"\"\"\n",
    "    As an AI assistant, my role is to meticulously analyze criminal justice documents and extract information about law enforcement personnel.\n",
    "\n",
    "    Query: {question}\n",
    "\n",
    "    Documents: {docs}\n",
    "\n",
    "    The response will contain:\n",
    "\n",
    "    1) The name of a law enforcement personnel. Law enforcement personnel can be identified by searching for these name prefixes: ofcs., officers, sergeants, sgts., lieutenants, lts., captains, cpts., commanders, sheriffs, deputies, dtys., detectives, dets., inspectors, technicians, analysts, coroners.\n",
    "\n",
    "    Please prefix the name with \"Officer Name: \".\n",
    "    For example, \"Officer Name: John Smith\".\n",
    "\n",
    "    2) If available, provide an in-depth description of the context of their mention.\n",
    "    If the context induces ambiguity regarding the individual's employment in law enforcement, please make this clear in your response.\n",
    "\n",
    "    Please prefix this information with \"Officer Context: \".\n",
    "\n",
    "    3) Review the context to discern the role of the officer. For example, Lead Detective (Homicide Division), Supervising Officer (Crime Lab), Detective, Officer on Scene, Arresting Officer, Crime Lab Analyst\n",
    "\n",
    "    Please prefix this information with \"Officer Role: \"\n",
    "    For example, \"Officer Role: Lead Detective\"\n",
    "\n",
    "    The full response should follow the format below, with no prefixes such as 1., 2., 3., a., b., c., etc.:\n",
    "\n",
    "    Officer Name: John Smith\n",
    "    Officer Context: Mentioned as someone who was present during a search, along with other detectives from different units.\n",
    "    Officer Role: Patrol Officer\n",
    "\n",
    "    Officer Name:\n",
    "    Officer Context:\n",
    "    Officer Role:\n",
    "\n",
    "    - Do not include any prefixes\n",
    "    - Only derive responses from factual information found within the police reports.\n",
    "    - If the context of an identified person's mention is not clear in the report, provide their name and note that the context is not specified.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Our prompt instructs the model to provide an \"in-depth description of the context of their mention\" and to \"discern the role of the officer,\" which helps in accurately categorizing individuals. Consider this output example taken from our results:\n",
    "\n",
    "Officer Name: Thomas Burns\n",
    "Officer Context: Mentioned in the obituaries as the father of Jamie Burns, who was the victim in the case.\n",
    "Officer Role: Not a law enforcement officer\n",
    "\n",
    "Here, the model initially extracted Thomas Burns as a potential law enforcement officer, demonstrating the tendency to over-extract names. However, our prompting technique mitigates this issue by requiring additional context. By leveraging our prompt's instruction to \"only derive responses from factual information found within the police reports\" and to make it clear \"if the context induces ambiguity regarding the individual's employment in law enforcement,\" we enable the model to provide crucial contextual information. By providing a clear mechanism to identify and remove non-officers from the final results, the low F1 scores due to poor precision rates less concerning in practice, because we can effectively identify and filter out non-law enforcement personnel in post-processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Insight <a class=\"anchor\" id=\"insights\"></a>\n",
    "\n",
    "The all pages analysis approach consistently outperformed other methods across all tested models. The full context approach, despite its theoretical potential, demonstrated significant limitations in practice. This is likely due to the many known issues associated with use of the full context window [3], including degraded retrieval performance with increasing context length, impaired reasoning capabilities over multiple facts, and susceptibility to information overload. Given that the NER-based approaches are essentially derivatives of the all pages method, and considering the superior performance of the all pages models, the rest of this post will focus exclusively on this approach.\n",
    "\n",
    "While the Mixtral models scored lower than their Claude counterparts, their performance is notable given Mixtral's ability to run locally, offering cost-effectiveness and data privacy benefits. Importantly, these scores were achieved using prompts originally designed for Claude, suggesting potential for further improvement with Mixtral-specific optimizations. This combination of solid performance, local execution capability, and room for optimization makes Mixtral models a compelling option for certain use cases, particularly when balancing performance against data privacy considerations.\n",
    "\n",
    "While the Mixtral models offer unique advantages in terms of local execution and data privacy, the Claude models were clearly the most performative. In particular, Claude 3 Haiku achieved an overall recall score of 0.912 (or 212 out of 232 entities correctly identified), on par with Claude Sonnet 3.5, despite being a much smaller model.\n",
    "\n",
    "To put this in perspective, Claude 3 Haiku correctly identified 16 out of 17 entities in a 227-page transcript document at a cost of \\$0.12, significanly lower than the costs of Claude 3.5 Sonnet (\\$1.53) and Claude 3 Opus (\\$7.65). A human performing the same task would take approximately 5 hours, assuming an average reading speed of 225 words per minute and additional time for entity identification. At a rate of \\$30 per hour, the human labor cost would be around \\$150. This stark contrast5 hours and \\$150 for a human versus near-instantaneous processing and \\$0.12 for Claude 3 Haikuunderscores the efficiency and cost-effectiveness of AI in such tasks.\n",
    "\n",
    "While the dollar cost comparison is useful for illustrating the advantages of large language models, the true value lies in the dramatic reallocation of human time and effort away from menial tasks and towards more creative work. We consider the entity extraction task of the LLM to be \"well-defined\" and menial because it consists of answering the same questions over and over: (1) Is this text a name? (2) If so, what is the role of the named entity? A human could be expected to perform well at this task, but the same amount of effort could be more effective when applied to something more complex. For instance, reviewing the context of an officer's mention to assess whether their actions reveal bias against a client, or incorporating this case information with other case files featuring the same officer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matched_count</th>\n",
       "      <th>n_entities</th>\n",
       "      <th>percentage_matched</th>\n",
       "      <th>matched_names</th>\n",
       "      <th>unmatched_names</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>f_beta_score</th>\n",
       "      <th>token_count</th>\n",
       "      <th>filetype</th>\n",
       "      <th>model</th>\n",
       "      <th>unique_entity_count</th>\n",
       "      <th>analysis_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'accardo', 'lawrence hingle', 'mangana', 'm. ...</td>\n",
       "      <td>set()</td>\n",
       "      <td>13</td>\n",
       "      <td>39</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>20475</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>13</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'martin venezia', 'ursin', 'little', 'ruiz'}</td>\n",
       "      <td>set()</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.392157</td>\n",
       "      <td>18718</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>4</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'john treadaway', \"harry o'neal\", 'mason spon...</td>\n",
       "      <td>set()</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1899</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>4</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'martin venezia', 'little', 'jerry ursin', 's...</td>\n",
       "      <td>set()</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>22254</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>6</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'martin venezia', 'henry kirsch', 'charles li...</td>\n",
       "      <td>set()</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>11696</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>10</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'john dillmann', 'tim sevzeneau', 'fred danta...</td>\n",
       "      <td>set()</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>7488</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>11</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'quinton', 'milton weaver', 'george serio', '...</td>\n",
       "      <td>set()</td>\n",
       "      <td>10</td>\n",
       "      <td>62</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>101239</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>10</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'gary sallienger', 'nate addison', 'lasalle r...</td>\n",
       "      <td>set()</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>10589</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>26</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'hilton cox', 'gebbia', 'allen tidwell', 'wal...</td>\n",
       "      <td>set()</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>14348</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>12</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'barrett morton', 'garner', 'kenneth leary'}</td>\n",
       "      <td>set()</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>41487</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>3</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>{'garrett', 'stewart', 'a sison', 'herman cade...</td>\n",
       "      <td>set()</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.425532</td>\n",
       "      <td>87361</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>8</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>96.774194</td>\n",
       "      <td>{'kerry granderson', 'michael fejka', 'byron a...</td>\n",
       "      <td>{'kerry farve'}</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>22021</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>31</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>{'ray miller', 'john miller', 'lambert', 'john...</td>\n",
       "      <td>{'tracy'}</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>88804</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>17</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>{'denour j', 'jerry hall', 'ralph peperone', '...</td>\n",
       "      <td>{'oneal'}</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>26172</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>13</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>90.625000</td>\n",
       "      <td>{'davillier', 'gebbia', 'walley goodey', 'char...</td>\n",
       "      <td>{'lynn anderson', 'doug gremillion', 'woodall'}</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>0.149485</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.450311</td>\n",
       "      <td>102827</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>32</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>{'ralph sacks', 'john morse', 'j. whitehurst',...</td>\n",
       "      <td>{'hanet crackum'}</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>7337</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>5</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>{'john dillman', 'sison', 'michae rice', 'john...</td>\n",
       "      <td>{'james ducose'}</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>7932</td>\n",
       "      <td>transcript</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>5</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>{'g. noble', 'raymond loosemore', 'jefferson',...</td>\n",
       "      <td>{'thomas sanders', \"harry o'neal\", 'patricia f...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>5871</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>11</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>27.272727</td>\n",
       "      <td>{'white', 'serio', 'anthony keeton'}</td>\n",
       "      <td>{'weaver', 'quinton', 'anderson', 'mosley', 'c...</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.205479</td>\n",
       "      <td>3748</td>\n",
       "      <td>report</td>\n",
       "      <td>claude-3-haiku-20240307</td>\n",
       "      <td>11</td>\n",
       "      <td>allpages_haiku</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    matched_count  n_entities  percentage_matched  \\\n",
       "18             13          13          100.000000   \n",
       "12              4           4          100.000000   \n",
       "17              4           4          100.000000   \n",
       "3               6           6          100.000000   \n",
       "16             10          10          100.000000   \n",
       "5              11          11          100.000000   \n",
       "15             10          10          100.000000   \n",
       "7              25          25          100.000000   \n",
       "13             12          12          100.000000   \n",
       "1               3           3          100.000000   \n",
       "11              8           8          100.000000   \n",
       "10             30          31           96.774194   \n",
       "9              16          17           94.117647   \n",
       "4              12          13           92.307692   \n",
       "2              29          32           90.625000   \n",
       "8               4           5           80.000000   \n",
       "6               4           5           80.000000   \n",
       "0               8          11           72.727273   \n",
       "14              3          11           27.272727   \n",
       "\n",
       "                                        matched_names  \\\n",
       "18  {'accardo', 'lawrence hingle', 'mangana', 'm. ...   \n",
       "12      {'martin venezia', 'ursin', 'little', 'ruiz'}   \n",
       "17  {'john treadaway', \"harry o'neal\", 'mason spon...   \n",
       "3   {'martin venezia', 'little', 'jerry ursin', 's...   \n",
       "16  {'martin venezia', 'henry kirsch', 'charles li...   \n",
       "5   {'john dillmann', 'tim sevzeneau', 'fred danta...   \n",
       "15  {'quinton', 'milton weaver', 'george serio', '...   \n",
       "7   {'gary sallienger', 'nate addison', 'lasalle r...   \n",
       "13  {'hilton cox', 'gebbia', 'allen tidwell', 'wal...   \n",
       "1       {'barrett morton', 'garner', 'kenneth leary'}   \n",
       "11  {'garrett', 'stewart', 'a sison', 'herman cade...   \n",
       "10  {'kerry granderson', 'michael fejka', 'byron a...   \n",
       "9   {'ray miller', 'john miller', 'lambert', 'john...   \n",
       "4   {'denour j', 'jerry hall', 'ralph peperone', '...   \n",
       "2   {'davillier', 'gebbia', 'walley goodey', 'char...   \n",
       "8   {'ralph sacks', 'john morse', 'j. whitehurst',...   \n",
       "6   {'john dillman', 'sison', 'michae rice', 'john...   \n",
       "0   {'g. noble', 'raymond loosemore', 'jefferson',...   \n",
       "14               {'white', 'serio', 'anthony keeton'}   \n",
       "\n",
       "                                      unmatched_names  true_positives  \\\n",
       "18                                              set()              13   \n",
       "12                                              set()               4   \n",
       "17                                              set()               4   \n",
       "3                                               set()               6   \n",
       "16                                              set()              10   \n",
       "5                                               set()              11   \n",
       "15                                              set()              10   \n",
       "7                                               set()              25   \n",
       "13                                              set()              12   \n",
       "1                                               set()               3   \n",
       "11                                              set()               8   \n",
       "10                                    {'kerry farve'}              30   \n",
       "9                                           {'tracy'}              16   \n",
       "4                                          {'oneal'}              12   \n",
       "2     {'lynn anderson', 'doug gremillion', 'woodall'}              29   \n",
       "8                                   {'hanet crackum'}               4   \n",
       "6                                    {'james ducose'}               4   \n",
       "0   {'thomas sanders', \"harry o'neal\", 'patricia f...               8   \n",
       "14  {'weaver', 'quinton', 'anderson', 'mosley', 'c...               3   \n",
       "\n",
       "    false_positives  precision    recall  f1_score  f_beta_score  token_count  \\\n",
       "18               39   0.250000  1.000000  0.400000      0.625000        20475   \n",
       "12               31   0.114286  1.000000  0.205128      0.392157        18718   \n",
       "17                6   0.400000  1.000000  0.571429      0.769231         1899   \n",
       "3                35   0.146341  1.000000  0.255319      0.461538        22254   \n",
       "16               16   0.384615  1.000000  0.555556      0.757576        11696   \n",
       "5                11   0.500000  1.000000  0.666667      0.833333         7488   \n",
       "15               62   0.138889  1.000000  0.243902      0.446429       101239   \n",
       "7                11   0.694444  1.000000  0.819672      0.919118        10589   \n",
       "13               17   0.413793  1.000000  0.585366      0.779221        14348   \n",
       "1                27   0.100000  1.000000  0.181818      0.357143        41487   \n",
       "11               54   0.129032  1.000000  0.228571      0.425532        87361   \n",
       "10               36   0.454545  0.967742  0.618557      0.789474        22021   \n",
       "9                52   0.235294  0.941176  0.376471      0.588235        88804   \n",
       "4                39   0.235294  0.923077  0.375000      0.582524        26172   \n",
       "2               165   0.149485  0.906250  0.256637      0.450311       102827   \n",
       "8                 9   0.307692  0.800000  0.444444      0.606061         7337   \n",
       "6                13   0.235294  0.800000  0.363636      0.540541         7932   \n",
       "0                 6   0.571429  0.727273  0.640000      0.689655         5871   \n",
       "14               26   0.103448  0.272727  0.150000      0.205479         3748   \n",
       "\n",
       "      filetype                    model  unique_entity_count   analysis_type  \n",
       "18      report  claude-3-haiku-20240307                   13  allpages_haiku  \n",
       "12  transcript  claude-3-haiku-20240307                    4  allpages_haiku  \n",
       "17  transcript  claude-3-haiku-20240307                    4  allpages_haiku  \n",
       "3   transcript  claude-3-haiku-20240307                    6  allpages_haiku  \n",
       "16      report  claude-3-haiku-20240307                   10  allpages_haiku  \n",
       "5       report  claude-3-haiku-20240307                   11  allpages_haiku  \n",
       "15  transcript  claude-3-haiku-20240307                   10  allpages_haiku  \n",
       "7       report  claude-3-haiku-20240307                   26  allpages_haiku  \n",
       "13      report  claude-3-haiku-20240307                   12  allpages_haiku  \n",
       "1   transcript  claude-3-haiku-20240307                    3  allpages_haiku  \n",
       "11  transcript  claude-3-haiku-20240307                    8  allpages_haiku  \n",
       "10      report  claude-3-haiku-20240307                   31  allpages_haiku  \n",
       "9   transcript  claude-3-haiku-20240307                   17  allpages_haiku  \n",
       "4       report  claude-3-haiku-20240307                   13  allpages_haiku  \n",
       "2   transcript  claude-3-haiku-20240307                   32  allpages_haiku  \n",
       "8       report  claude-3-haiku-20240307                    5  allpages_haiku  \n",
       "6   transcript  claude-3-haiku-20240307                    5  allpages_haiku  \n",
       "0       report  claude-3-haiku-20240307                   11  allpages_haiku  \n",
       "14      report  claude-3-haiku-20240307                   11  allpages_haiku  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku_tbl = df[df.analysis_type.str.contains(\"allpages_haiku\")]\n",
    "haiku_tbl.sort_values(\"percentage_matched\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Insights <a class=\"anchor\" id=\"xtra\"></a>\n",
    "\n",
    "Building on our initial findings, we aimed to better understand what caused the performance differences between Claude and Mixtral models in the all pages method. Our additional analysis looks at two key areas:\n",
    "\n",
    "1. Entity Complexity: An examination of how Claude and Mixtral models differ in handling single-word versus multi-word entities.\n",
    "2. Feature Importance: An evaluation of which input characteristics most significantly influence the performance of Claude and Mixtral models. \n",
    "\n",
    "Entity Complexity\n",
    "\n",
    "**Claude Models Performance**:\n",
    "   - Claude 3.5 Sonnet showed the best overall performance, with the lowest percentage of unmatched single-word entities (18.18%) and a very low percentage of unmatched multi-word entities (5.08%).\n",
    "   - Claude 3 Haiku performed similarly well, with slightly higher unmatched percentages (20.00% for single-word and 5.08% for multi-word entities).\n",
    "\n",
    "**Mixtral Models Performance**:\n",
    "   - Both Mixtral models showed higher percentages of unmatched entities compared to the Claude models.\n",
    "   - Mixtral 7B performed better than Mixtral 22B in both single-word and multi-word entity extraction.\n",
    "   - Mixtral 22B had the highest percentage of unmatched entities for both single-word (36.36%) and multi-word (22.03%) categories.\n",
    "\n",
    "**Single-Word vs. Multi-Word Entity Extraction**:\n",
    "   - All models generally performed better in extracting multi-word entities compared to single-word entities, as evidenced by the lower percentage of unmatched multi-word entities across all models.\n",
    "   - This trend was particularly pronounced in the Claude models, which showed a significant performance gap between single-word and multi-word entity extraction.\n",
    "\n",
    "**Model Size and Performance**:\n",
    "   - Interestingly, the larger Mixtral 22B model underperformed compared to its smaller 7B counterpart. This suggests that larger model size doesn't always correlate with better performance in specific tasks like entity extraction.\n",
    "   - In contrast, the more advanced Claude 3.5 Sonnet slightly outperformed Claude 3 Haiku in single-word entity extraction, while performing equally well in multi-word entity extraction.\n",
    "\n",
    "**Vision Models Performance**:\n",
    "   - The vision-based models showed notably higher percentages of unmatched entities compared to their text-only counterparts.\n",
    "   - Claude 3.5 Sonnet Vision performed slightly better than Claude 3 Haiku Vision in single-word entity extraction (37.04% vs 40.74% unmatched), while both had identical performance for multi-word entities (32.74% unmatched)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis Type</th>\n",
       "      <th>total_single_word_entities</th>\n",
       "      <th>total_multi_word_entities</th>\n",
       "      <th>unmatched_single_word_entities</th>\n",
       "      <th>unmatched_multi_word_entities</th>\n",
       "      <th>pct_unmatched_single_word</th>\n",
       "      <th>pct_unmatched_multi_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>22.159091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>29.090909</td>\n",
       "      <td>15.340909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>55</td>\n",
       "      <td>176</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>18.181818</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>haiku_vision_allpages</td>\n",
       "      <td>54</td>\n",
       "      <td>167</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>40.740741</td>\n",
       "      <td>32.335329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sonnet_vision_allpages</td>\n",
       "      <td>54</td>\n",
       "      <td>167</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>37.037037</td>\n",
       "      <td>32.335329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Analysis Type  total_single_word_entities  \\\n",
       "0           allpages_haiku                          55   \n",
       "1     allpages_mixtral_22b                          55   \n",
       "2      allpages_mixtral_7b                          55   \n",
       "3          allpages_sonnet                          55   \n",
       "8    haiku_vision_allpages                          54   \n",
       "21  sonnet_vision_allpages                          54   \n",
       "\n",
       "    total_multi_word_entities  unmatched_single_word_entities  \\\n",
       "0                         176                              11   \n",
       "1                         176                              20   \n",
       "2                         176                              16   \n",
       "3                         176                              10   \n",
       "8                         167                              22   \n",
       "21                        167                              20   \n",
       "\n",
       "    unmatched_multi_word_entities  pct_unmatched_single_word  \\\n",
       "0                               8                  20.000000   \n",
       "1                              39                  36.363636   \n",
       "2                              27                  29.090909   \n",
       "3                               8                  18.181818   \n",
       "8                              54                  40.740741   \n",
       "21                             54                  37.037037   \n",
       "\n",
       "    pct_unmatched_multi_word  \n",
       "0                   4.545455  \n",
       "1                  22.159091  \n",
       "2                  15.340909  \n",
       "3                   4.545455  \n",
       "8                  32.335329  \n",
       "21                 32.335329  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_entity_characteristics(df):\n",
    "    results = []\n",
    "\n",
    "    for analysis_type, group in df.groupby('analysis_type'):\n",
    "        all_entities = []\n",
    "        matched_entities = []\n",
    "        unmatched_entities = []\n",
    "\n",
    "        for _, row in group.iterrows():\n",
    "            matched = set(literal_eval(row['matched_names']))\n",
    "            unmatched = set(literal_eval(row['unmatched_names']))\n",
    "            all_entities.extend(matched.union(unmatched))\n",
    "            matched_entities.extend(matched)\n",
    "            unmatched_entities.extend(unmatched)\n",
    "\n",
    "        def categorize_entities(entities):\n",
    "            single_word = [e for e in entities if len(e.split()) == 1]\n",
    "            multi_word = [e for e in entities if len(e.split()) > 1]\n",
    "            return single_word, multi_word\n",
    "\n",
    "        all_single, all_multi = categorize_entities(all_entities)\n",
    "        matched_single, matched_multi = categorize_entities(matched_entities)\n",
    "\n",
    "        total_single = len(all_single)\n",
    "        total_multi = len(all_multi)\n",
    "\n",
    "        unmatched_single = total_single - len(matched_single)\n",
    "        unmatched_multi = total_multi - len(matched_multi)\n",
    "\n",
    "        pct_unmatched_single = (unmatched_single / total_single) * 100 if total_single > 0 else 0\n",
    "        pct_unmatched_multi = (unmatched_multi / total_multi) * 100 if total_multi > 0 else 0\n",
    "\n",
    "        results.append({\n",
    "            'Analysis Type': analysis_type,\n",
    "            'total_single_word_entities': total_single,\n",
    "            'total_multi_word_entities': total_multi,\n",
    "            'unmatched_single_word_entities': unmatched_single,\n",
    "            'unmatched_multi_word_entities': unmatched_multi,\n",
    "            'pct_unmatched_single_word': pct_unmatched_single,\n",
    "            'pct_unmatched_multi_word': pct_unmatched_multi\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Assuming all_data is your input DataFrame\n",
    "analysis_comparison_df = analyze_entity_characteristics(df)\n",
    "analysis_comparison_df.to_csv(\"../data/output/compare.csv\")\n",
    "\n",
    "analysis_comparison_df =  analysis_comparison_df[analysis_comparison_df[\"Analysis Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "analysis_comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis <a class=\"anchor\" id=\"importance\"></a>\n",
    "\n",
    "To determine which features are most important in our models, we've established an absolute threshold of 0.3333. This threshold represents the weighted mean of the importance scores for our three features across all models and document types, with weights based on each model's R score. This approach ensures that features from better-performing models have a stronger influence on the threshold. The R score, ranging from 0 to 1, indicates how well each model fits the data, with higher scores suggesting better predictive performance. Features with importance scores above the 0.3333 threshold are considered crucial, while those below are less influential. Generally, an R score above 0.7 is considered good, above 0.8 is very good, and above 0.9 is excellent.\n",
    "\n",
    "Haiku: Reports Documents (R = 0.877703)\n",
    "\n",
    "- Average entity length: 0.473659\n",
    "- Percent single-word entities: 0.315517\n",
    "- Percent multi-word entities: 0.210824\n",
    "\n",
    "Haiku: Transcript Documents (R = 0.430431)\n",
    "\n",
    "- Percent single-word entities: 0.343402\n",
    "- Average entity length: 0.362066\n",
    "- Percent multi-word entities: 0.294532\n",
    "\n",
    "Sonnet 3.5: Report Documents (R = 0.878340)\n",
    "\n",
    "- Percent single-word entities: 0.480449\n",
    "- Average entity length: 0.417674\n",
    "- Percent multi-word entities: 0.101878\n",
    "\n",
    "Sonnet 3.5: Transcript Documents (R = 0.735393)\n",
    "\n",
    "- Percent single-word entities: 0.362551\n",
    "- Percent multi-word entities: 0.316958\n",
    "- Average entity length: 0.320490\n",
    "\n",
    "Mixtral 7B: Report Documents (R = 0.830598)\n",
    "\n",
    "- Percent single-word entities: 0.382679\n",
    "- Percent multi-word entities: 0.315237\n",
    "- Average entity length: 0.302084\n",
    "\n",
    "Mixtral 7B: Transcript Documents (R = 0.653290)\n",
    "\n",
    "- Average entity length: 0.368870\n",
    "- Percent multi-word entities: 0.345037\n",
    "- Percent single-word entities: 0.286093\n",
    "\n",
    "Mixtral 22B: Report Documents (R = 0.810837)\n",
    "\n",
    "- Average entity length: 0.430078\n",
    "- Percent single-word entities: 0.295253\n",
    "- Percent multi-word entities: 0.274669\n",
    "\n",
    "Mixtral 22B: Transcript Documents (R = 0.399489)\n",
    "\n",
    "- Percent single-word entities: 0.373366\n",
    "- Average entity length: 0.358676\n",
    "- Percent multi-word entities: 0.267959\n",
    "\n",
    "Haiku Vision: Report Documents (R = 0.793277)\n",
    "\n",
    "- Percent single-word entities: 0.440825\n",
    "- Percent multi-word entities: 0.304457\n",
    "- Average entity length: 0.254718\n",
    "\n",
    "Haiku Vision: Transcript Documents (R = 0.687107)\n",
    "\n",
    "- Percent single-word entities: 0.357500\n",
    "- Average entity length: 0.347589\n",
    "- Percent multi-word entities: 0.294911\n",
    "\n",
    "Sonnet 3.5 Vision: Report Documents (R = 0.819167)\n",
    "\n",
    "- Average entity length: 0.405732\n",
    "- Percent single-word entities: 0.298099\n",
    "- Percent multi-word entities: 0.296169\n",
    "\n",
    "Sonnet Vision: Transcript Documents (R = 0.596324)\n",
    "\n",
    "- Percent single-word entities: 0.339809\n",
    "- Percent multi-word entities: 0.336296\n",
    "- Average entity length: 0.323894\n",
    "\n",
    "The R score for most models in this analysis fall in the good to very good range for report documents, while transcript documents show more varied performance. We examined three features: average entity length, the percentage of single-word entities, and the percentage of multi-word entities. These features often exceed or approach the 0.3333 threshold, indicating their significance in predicting the f-beta score. Across most models, the percentage of single-word entities tends to have high feature importance, particularly for report documents. However, there's notable variation between models and document types. For instance, Haiku and Sonnet models often show higher importance for average entity length in report documents, while Mixtral models show more balanced distribution across features. This suggests that while all three features are significant, their relative impact on the f-beta score prediction differs between models and document types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Mean Feature Importances:\n",
      "Average Entity Length: 0.3009\n",
      "Percent Multi-Word Entities: 0.3092\n",
      "Percent Single-Word Entities: 0.3899\n",
      "\n",
      "Absolute Threshold for Importance: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Analysis_Type</th>\n",
       "      <th>Document_Type</th>\n",
       "      <th>NER_Percentage</th>\n",
       "      <th>Average_F_Beta_Score</th>\n",
       "      <th>Average_RMSE</th>\n",
       "      <th>Average_R2</th>\n",
       "      <th>Average_Entities_Per_Token</th>\n",
       "      <th>Average_Entity_Length</th>\n",
       "      <th>Percent_Multi_Word_Entities</th>\n",
       "      <th>avg_entity_length</th>\n",
       "      <th>pct_multi_word_entities</th>\n",
       "      <th>pct_single_word_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.678744</td>\n",
       "      <td>0.055453</td>\n",
       "      <td>0.912587</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.280603</td>\n",
       "      <td>0.249036</td>\n",
       "      <td>0.470360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allpages_haiku</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.492346</td>\n",
       "      <td>0.044883</td>\n",
       "      <td>0.855869</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1.701879</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.318615</td>\n",
       "      <td>0.306501</td>\n",
       "      <td>0.374885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.593864</td>\n",
       "      <td>0.055804</td>\n",
       "      <td>0.856801</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.330407</td>\n",
       "      <td>0.349754</td>\n",
       "      <td>0.319839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allpages_mixtral_22b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.316368</td>\n",
       "      <td>0.083998</td>\n",
       "      <td>0.738233</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1.701879</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.262648</td>\n",
       "      <td>0.229920</td>\n",
       "      <td>0.507433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.534272</td>\n",
       "      <td>0.064669</td>\n",
       "      <td>0.857118</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.245634</td>\n",
       "      <td>0.300830</td>\n",
       "      <td>0.453536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>allpages_mixtral_7b</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.292296</td>\n",
       "      <td>0.057685</td>\n",
       "      <td>0.825753</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1.701879</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.286402</td>\n",
       "      <td>0.340560</td>\n",
       "      <td>0.373038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>0.883384</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>1.797343</td>\n",
       "      <td>0.779161</td>\n",
       "      <td>0.325290</td>\n",
       "      <td>0.306120</td>\n",
       "      <td>0.368591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allpages_sonnet</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.729048</td>\n",
       "      <td>0.041313</td>\n",
       "      <td>0.869422</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>1.701879</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.319539</td>\n",
       "      <td>0.340838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>haiku_vision_allpages</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.536223</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.810213</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.785937</td>\n",
       "      <td>0.765735</td>\n",
       "      <td>0.245715</td>\n",
       "      <td>0.349370</td>\n",
       "      <td>0.404915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>haiku_vision_allpages</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>0.080939</td>\n",
       "      <td>0.769691</td>\n",
       "      <td>0.870755</td>\n",
       "      <td>1.701879</td>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.322037</td>\n",
       "      <td>0.286276</td>\n",
       "      <td>0.391687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sonnet_vision_allpages</td>\n",
       "      <td>report</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.571309</td>\n",
       "      <td>0.106881</td>\n",
       "      <td>0.816565</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.759179</td>\n",
       "      <td>0.736452</td>\n",
       "      <td>0.357063</td>\n",
       "      <td>0.332631</td>\n",
       "      <td>0.310306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>sonnet_vision_allpages</td>\n",
       "      <td>transcript</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.578180</td>\n",
       "      <td>0.093703</td>\n",
       "      <td>0.695767</td>\n",
       "      <td>1.150232</td>\n",
       "      <td>1.731691</td>\n",
       "      <td>0.725441</td>\n",
       "      <td>0.291441</td>\n",
       "      <td>0.340225</td>\n",
       "      <td>0.368333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Analysis_Type Document_Type NER_Percentage  Average_F_Beta_Score  \\\n",
       "0           allpages_haiku        report            N/A              0.678744   \n",
       "1           allpages_haiku    transcript            N/A              0.492346   \n",
       "2     allpages_mixtral_22b        report            N/A              0.593864   \n",
       "3     allpages_mixtral_22b    transcript            N/A              0.316368   \n",
       "4      allpages_mixtral_7b        report            N/A              0.534272   \n",
       "5      allpages_mixtral_7b    transcript            N/A              0.292296   \n",
       "6          allpages_sonnet        report            N/A              0.776365   \n",
       "7          allpages_sonnet    transcript            N/A              0.729048   \n",
       "16   haiku_vision_allpages        report            N/A              0.536223   \n",
       "17   haiku_vision_allpages    transcript            N/A              0.542300   \n",
       "42  sonnet_vision_allpages        report            N/A              0.571309   \n",
       "43  sonnet_vision_allpages    transcript            N/A              0.578180   \n",
       "\n",
       "    Average_RMSE  Average_R2  Average_Entities_Per_Token  \\\n",
       "0       0.055453    0.912587                    0.001355   \n",
       "1       0.044883    0.855869                    0.000443   \n",
       "2       0.055804    0.856801                    0.001355   \n",
       "3       0.083998    0.738233                    0.000443   \n",
       "4       0.064669    0.857118                    0.001355   \n",
       "5       0.057685    0.825753                    0.000443   \n",
       "6       0.047625    0.883384                    0.001355   \n",
       "7       0.041313    0.869422                    0.000443   \n",
       "16      0.106771    0.810213                         inf   \n",
       "17      0.080939    0.769691                    0.870755   \n",
       "42      0.106881    0.816565                         inf   \n",
       "43      0.093703    0.695767                    1.150232   \n",
       "\n",
       "    Average_Entity_Length  Percent_Multi_Word_Entities  avg_entity_length  \\\n",
       "0                1.797343                     0.779161           0.280603   \n",
       "1                1.701879                     0.694935           0.318615   \n",
       "2                1.797343                     0.779161           0.330407   \n",
       "3                1.701879                     0.694935           0.262648   \n",
       "4                1.797343                     0.779161           0.245634   \n",
       "5                1.701879                     0.694935           0.286402   \n",
       "6                1.797343                     0.779161           0.325290   \n",
       "7                1.701879                     0.694935           0.339623   \n",
       "16               1.785937                     0.765735           0.245715   \n",
       "17               1.701879                     0.694935           0.322037   \n",
       "42               1.759179                     0.736452           0.357063   \n",
       "43               1.731691                     0.725441           0.291441   \n",
       "\n",
       "    pct_multi_word_entities  pct_single_word_entities  \n",
       "0                  0.249036                  0.470360  \n",
       "1                  0.306501                  0.374885  \n",
       "2                  0.349754                  0.319839  \n",
       "3                  0.229920                  0.507433  \n",
       "4                  0.300830                  0.453536  \n",
       "5                  0.340560                  0.373038  \n",
       "6                  0.306120                  0.368591  \n",
       "7                  0.319539                  0.340838  \n",
       "16                 0.349370                  0.404915  \n",
       "17                 0.286276                  0.391687  \n",
       "42                 0.332631                  0.310306  \n",
       "43                 0.340225                  0.368333  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_entity_complexity_features(row):\n",
    "    matched = set(literal_eval(row['matched_names']))\n",
    "    unmatched = set(literal_eval(row['unmatched_names']))\n",
    "    all_entities = matched.union(unmatched)\n",
    "\n",
    "    if all_entities:\n",
    "        avg_entity_length = np.mean([len(entity.split()) for entity in all_entities])\n",
    "        pct_multi_word = sum(len(entity.split()) > 1 for entity in all_entities) / len(all_entities)\n",
    "        pct_single_word = sum(len(entity.split()) == 1 for entity in all_entities) / len(all_entities)\n",
    "    else:\n",
    "        avg_entity_length = 0\n",
    "        pct_multi_word = 0\n",
    "        pct_single_word = 0\n",
    "\n",
    "    return pd.Series({\n",
    "        'avg_entity_length': avg_entity_length,\n",
    "        'pct_multi_word_entities': pct_multi_word,\n",
    "        'pct_single_word_entities': pct_single_word\n",
    "    })\n",
    "\n",
    "def analyze_data(data):\n",
    "    complexity_features = data.apply(calculate_entity_complexity_features, axis=1)\n",
    "    data = pd.concat([data, complexity_features], axis=1)\n",
    "\n",
    "    data['entities_per_token'] = data['n_entities'] / data['token_count']\n",
    "\n",
    "    X = data[['avg_entity_length', 'pct_multi_word_entities', 'pct_single_word_entities']]\n",
    "    y = data['f_beta_score']\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    predictions = rf.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, predictions))\n",
    "    r2 = r2_score(y, predictions)\n",
    "\n",
    "    importances = rf.feature_importances_\n",
    "    feature_names = X.columns\n",
    "\n",
    "    feature_importances = {name: importance for name, importance in zip(feature_names, importances)}\n",
    "\n",
    "    return rmse, r2, feature_importances, data\n",
    "\n",
    "def process_data(data):\n",
    "    results = []\n",
    "    for analysis_type, group in data.groupby('analysis_type'):\n",
    "        if 'filetype' in group.columns:\n",
    "            doc_types = group['filetype'].unique()\n",
    "        else:\n",
    "            doc_types = ['combined']\n",
    "\n",
    "        for doc_type in doc_types:\n",
    "            if doc_type != 'combined':\n",
    "                filtered_data = group[group['filetype'] == doc_type]\n",
    "            else:\n",
    "                filtered_data = group\n",
    "\n",
    "            if not filtered_data.empty:\n",
    "                rmse, r2, feature_importances, updated_data = analyze_data(filtered_data)\n",
    "                result = {\n",
    "                    'Analysis_Type': analysis_type,\n",
    "                    'Document_Type': doc_type,\n",
    "                    'Average_F_Beta_Score': updated_data['f_beta_score'].mean(),\n",
    "                    'Average_RMSE': rmse,\n",
    "                    'Average_R2': r2,\n",
    "                    'Average_Entities_Per_Token': updated_data['entities_per_token'].mean(),\n",
    "                    'Average_Entity_Length': updated_data['avg_entity_length'].mean(),\n",
    "                    'Percent_Multi_Word_Entities': updated_data['pct_multi_word_entities'].mean(),\n",
    "                    **feature_importances\n",
    "                }\n",
    "\n",
    "                # Extract NER percentage if it's an NER analysis type\n",
    "                if 'ner' in analysis_type:\n",
    "                    result['NER_Percentage'] = analysis_type.split('_')[1]\n",
    "                else:\n",
    "                    result['NER_Percentage'] = 'N/A'\n",
    "\n",
    "                results.append(result)\n",
    "    return results\n",
    "\n",
    "def calculate_weighted_mean_feature_importances(grouped_results_df):\n",
    "    weighted_feature_importances = {\n",
    "        'Average Entity Length': [],\n",
    "        'Percent Multi-Word Entities': [],\n",
    "        'Percent Single-Word Entities': []\n",
    "    }\n",
    "    weights = []\n",
    "\n",
    "    for index, row in grouped_results_df.iterrows():\n",
    "        weight = row['Average_R2']\n",
    "        weighted_feature_importances['Average Entity Length'].append(row['avg_entity_length'] * weight)\n",
    "        weighted_feature_importances['Percent Multi-Word Entities'].append(row['pct_multi_word_entities'] * weight)\n",
    "        weighted_feature_importances['Percent Single-Word Entities'].append(row['pct_single_word_entities'] * weight)\n",
    "        weights.append(weight)\n",
    "\n",
    "    total_weight = sum(weights)\n",
    "    weighted_mean_feature_importances = {\n",
    "        feature: sum(values) / total_weight\n",
    "        for feature, values in weighted_feature_importances.items()\n",
    "    }\n",
    "\n",
    "    return weighted_mean_feature_importances\n",
    "\n",
    "\n",
    "results = process_data(df_names)\n",
    "results_df = pd.DataFrame(results)\n",
    "groupby_columns = ['Analysis_Type', 'Document_Type', 'NER_Percentage']\n",
    "grouped_results_df = results_df.groupby(groupby_columns).mean().reset_index()\n",
    "grouped_results_df = grouped_results_df[grouped_results_df[\"Analysis_Type\"].str.contains(\"allpages\")]\n",
    "\n",
    "weighted_mean_feature_importances = calculate_weighted_mean_feature_importances(grouped_results_df)\n",
    "print(\"Weighted Mean Feature Importances:\")\n",
    "for feature, importance in weighted_mean_feature_importances.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# Calculate and print the absolute threshold\n",
    "absolute_threshold = sum(weighted_mean_feature_importances.values()) / len(weighted_mean_feature_importances)\n",
    "print(f\"\\nAbsolute Threshold for Importance: {absolute_threshold:.4f}\")\n",
    "\n",
    "grouped_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a class=\"anchor\" id=\"conclusion\"></a>\n",
    "\n",
    "While LLMs demonstrate impressive capabilities in entity extraction, it's important to recognize the unique strengths of human analysis in information processing. Humans prioritize information based on its utility for decision-making, assigning higher value to details that increase their insight and understanding of a situation [4]. In the context of legal document analysis, human readers excel at intuitively identifying and focusing on the most crucial information, even if they might miss some less critical entities (e.g. extracting 16 our of 17 entities from a 185-page document). Although LLMs initially lack this intuitive prioritization, we can design iterative pipelines that approximate human-like behavior. By implementing a multi-pass approach - first using LLMs for broad entity extraction, then refining the focus based on initial findings - we can simulate the human ability to hone in on critical information. This approach combines the speed and consistency of LLMs with a more nuanced, human-like discernment of importance, enabling efficient processing of vast document corpora while ensuring the most valuable information is identified and prioritized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources <a class=\"anchor\" id=\"links\"></a>\n",
    "\n",
    "---\n",
    "\n",
    "[1] The Future of Computational Law. Cross-disciplinary Research in Computational Law (CRCL), 2(2) (https://journalcrcl.org/crcl/article/view/62/28).\n",
    "\n",
    "[2] Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools (https://arxiv.org/pdf/2405.20362).\n",
    "\n",
    "[3] Multi Needle in a Haystack (https://blog.langchain.dev/multi-needle-in-a-haystack/).\n",
    "\n",
    "[4] Information overload in the information age: a review of the literature from business administration, business psychology, and related disciplines with a bibliometric approach and framework development (https://link.springer.com/article/10.1007/s40685-018-0069-z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "More on this series:\n",
    "\n",
    "Read our [first chapter](https://hrdag.org/tech-notes/large-language-models-IPNO.html) or [Part 2](TODO: add link to Part 2) of this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
